#!/usr/bin/env bash
# Push Validator Manager - Native Only Version
# Completely Docker-free Push Chain validator management

set -euo pipefail
IFS=$'\n\t'

# Resolve script directory robustly, following symlinks
SCRIPT_SOURCE="${BASH_SOURCE[0]}"
while [ -h "$SCRIPT_SOURCE" ]; do
  BASE_DIR="$(cd -P "$(dirname "$SCRIPT_SOURCE")" && pwd)"
  SCRIPT_SOURCE="$(readlink "$SCRIPT_SOURCE")"
  [[ "$SCRIPT_SOURCE" != /* ]] && SCRIPT_SOURCE="$BASE_DIR/$SCRIPT_SOURCE"
done
SCRIPT_DIR="$(cd -P "$(dirname "$SCRIPT_SOURCE")" && pwd)"
cd "$SCRIPT_DIR"

# Load environment variables from .env if it exists (robust, supports spaces)
if [ -f "$SCRIPT_DIR/.env" ]; then
    set -a
    . "$SCRIPT_DIR/.env"
    set +a
fi

# Colors for output - Standardized palette
GREEN='\033[0;32m'      # Success messages
RED='\033[0;31m'        # Error messages  
YELLOW='\033[0;33m'     # Warning messages
CYAN='\033[0;36m'       # Status/info messages
BLUE='\033[1;94m'       # Headers/titles (bright blue)
MAGENTA='\033[0;35m'    # Accent/highlight data
WHITE='\033[1;37m'      # Important values (bold white)
NC='\033[0m'            # No color/reset
BOLD='\033[1m'          # Emphasis
DIM='\033[90m'          # Dim gray (for empty bar)

# Print functions - Unified across all scripts
print_status() {
    echo -e "${CYAN}$1${NC}"
}

print_header() {
    echo -e "${BLUE}$1${NC}"
}

print_value() {
    echo -e "${MAGENTA}$1${NC}"
}

print_success() {
    echo -e "${GREEN}$1${NC}"
}

print_error() {
    echo -e "${RED}$1${NC}"
}

print_warning() {
    echo -e "${YELLOW}$1${NC}"
}

# Compute a reasonable progress bar width based on terminal size
# Override with PROGRESS_BAR_WIDTH env var (10..100)
compute_bar_width() {
    local override="${PROGRESS_BAR_WIDTH:-}"
    if [[ "$override" =~ ^[0-9]+$ ]] && [ "$override" -ge 10 ] && [ "$override" -le 100 ]; then
        echo "$override"
        return 0
    fi
    local cols=80
    if [ -t 1 ]; then
        cols=$(tput cols 2>/dev/null || echo 80)
        [[ "$cols" =~ ^[0-9]+$ ]] || cols=80
    fi
    if [ "$cols" -ge 140 ]; then
        echo 50
    elif [ "$cols" -ge 100 ]; then
        echo 40
    else
        echo 30
    fi
}

# Enhanced progress bar utilities for state sync and block sync
render_progress_bar() {
    local percentage="$1"
    local bar_width="${2:-$(compute_bar_width)}"
    local filled_char="${3:-█}"
    local empty_char="${4:-░}"
    local color="${5:-${GREEN}}"
    
    # Ensure percentage is numeric and within bounds
    [[ "$percentage" =~ ^[0-9]+\.?[0-9]*$ ]] || percentage="0"
    local percentage_int=$(echo "$percentage" | cut -d'.' -f1)
    [ "$percentage_int" -gt 100 ] && percentage_int=100
    [ "$percentage_int" -lt 0 ] && percentage_int=0
    
    local filled=$(echo "$percentage_int * $bar_width / 100" | bc 2>/dev/null | cut -d'.' -f1)
    [ -z "$filled" ] && filled=0
    
    # Ensure at least 1 cell shows when progress > 0
    if [ "$filled" -eq 0 ] && [ "$percentage_int" -gt 0 ]; then
        filled=1
    fi
    [ "$filled" -gt "$bar_width" ] && filled=$bar_width
    
    local empty=$((bar_width - filled))
    local bar_filled=$(printf "%0.s${filled_char}" $(seq 1 ${filled}))
    local bar_empty=$(printf "%0.s${empty_char}" $(seq 1 ${empty}))
    
    echo "${color}${bar_filled}${NC}${DIM}${bar_empty}${NC}"
}

# Show phase-based progress for multi-stage operations
show_phase_progress() {
    local phase_name="$1"
    local phase_number="$2"
    local total_phases="$3"
    local phase_percentage="$4"
    local status_text="${5:-}"
    local show_bar="${6:-true}"
    
    local overall_progress=0
    if [ "$total_phases" -gt 0 ]; then
        # Calculate overall progress based on completed phases plus current phase progress
        local completed_phases=$((phase_number - 1))
        overall_progress=$(echo "scale=1; ($completed_phases * 100 + $phase_percentage) / $total_phases" | bc 2>/dev/null || echo "0")
    fi
    
    if [ "$show_bar" = "true" ]; then
        local progress_bar=$(render_progress_bar "$overall_progress")
        printf "\r"
        echo -en "${CYAN}${phase_name}${NC} (${BOLD}${phase_number}${NC}/${BOLD}${total_phases}${NC}) [${progress_bar}] ${GREEN}${overall_progress}%${NC}"
    else
        printf "\r"
        echo -en "${CYAN}${phase_name}${NC} (${BOLD}${phase_number}${NC}/${BOLD}${total_phases}${NC}) ${GREEN}${overall_progress}%${NC}"
    fi
    
    if [ -n "$status_text" ]; then
        echo -en " | ${status_text}"
    fi
    echo -en "\033[K"  # Clear to end of line
}

# Show peer discovery progress
show_peer_discovery_progress() {
    local peers_found="$1"
    local peers_target="${2:-10}"
    local elapsed_seconds="$3"
    local timeout_seconds="${4:-30}"
    
    local percentage=0
    if [ "$peers_target" -gt 0 ]; then
        percentage=$(echo "scale=1; 100 * $peers_found / $peers_target" | bc 2>/dev/null || echo "0")
    fi
    
    # Also consider time-based progress
    local time_progress=0
    if [ "$timeout_seconds" -gt 0 ]; then
        time_progress=$(echo "scale=1; 100 * $elapsed_seconds / $timeout_seconds" | bc 2>/dev/null || echo "0")
    fi
    
    # Use the higher of the two progress indicators
    local display_progress="$percentage"
    if [ "$(echo "$time_progress > $percentage" | bc 2>/dev/null || echo 0)" -eq 1 ]; then
        display_progress="$time_progress"
    fi
    
    local status_text="${BOLD}${WHITE}Peers${NC} ${MAGENTA}${peers_found}${NC}/${MAGENTA}${peers_target}${NC}"
    if [ "$elapsed_seconds" -gt 0 ]; then
        status_text="$status_text | ${BOLD}${WHITE}Time${NC} ${CYAN}${elapsed_seconds}s${NC}"
    fi
    
    show_phase_progress "🔍 Discovering peers" 1 3 "$display_progress" "$status_text"
}

# Show snapshot download progress
show_snapshot_progress() {
    local downloaded_mb="${1:-0}"
    local total_mb="${2:-0}"
    local speed_mbps="${3:-0}"
    
    local percentage=0
    if [ "$total_mb" -gt 0 ]; then
        percentage=$(echo "scale=1; 100 * $downloaded_mb / $total_mb" | bc 2>/dev/null || echo "0")
    fi
    
    local status_text=""
    if [ "$total_mb" -gt 0 ]; then
        status_text="${BOLD}${WHITE}Download${NC} ${MAGENTA}${downloaded_mb}MB${NC}/${MAGENTA}${total_mb}MB${NC}"
    else
        status_text="${BOLD}${WHITE}Downloading${NC} ${MAGENTA}${downloaded_mb}MB${NC}"
    fi
    
    if [ "$(echo "$speed_mbps > 0" | bc 2>/dev/null || echo 0)" -eq 1 ]; then
        status_text="$status_text | ${BOLD}${WHITE}Speed${NC} ${CYAN}${speed_mbps}MB/s${NC}"
        
        # Calculate ETA if we know total size
        if [ "$total_mb" -gt 0 ] && [ "$(echo "$speed_mbps > 0" | bc 2>/dev/null || echo 0)" -eq 1 ]; then
            local remaining_mb=$(echo "$total_mb - $downloaded_mb" | bc 2>/dev/null || echo "0")
            if [ "$(echo "$remaining_mb > 0" | bc 2>/dev/null || echo 0)" -eq 1 ]; then
                local eta_seconds=$(echo "scale=0; $remaining_mb / $speed_mbps" | bc 2>/dev/null || echo "0")
                if [ "$eta_seconds" -gt 0 ]; then
                    local eta_min=$((eta_seconds / 60))
                    local eta_sec=$((eta_seconds % 60))
                    if [ "$eta_min" -gt 0 ]; then
                        status_text="$status_text | ${BOLD}${WHITE}ETA${NC} ${GREEN}${eta_min}m${eta_sec}s${NC}"
                    else
                        status_text="$status_text | ${BOLD}${WHITE}ETA${NC} ${GREEN}${eta_sec}s${NC}"
                    fi
                fi
            fi
        fi
    fi
    
    show_phase_progress "📦 Downloading snapshot" 2 3 "$percentage" "$status_text"
}

# Enhanced state sync phase detection from logs
detect_state_sync_phase() {
    local log_file="$HOME_DIR/logs/pchaind.log"
    [ ! -f "$log_file" ] && echo "unknown" && return
    
    # Get recent log entries (last 50 lines for performance)
    local recent_logs=$(tail -50 "$log_file" 2>/dev/null || echo "")
    [ -z "$recent_logs" ] && echo "unknown" && return
    
    # Phase detection based on log patterns (ordered by priority)
    if echo "$recent_logs" | grep -qi "Starting state sync\|state sync.*starting"; then
        echo "starting"
    elif echo "$recent_logs" | grep -qi "Discovering snapshots\|snapshot.*discovery"; then
        echo "peer_discovery"
    elif echo "$recent_logs" | grep -qi "Discovered.*snapshot\|Found.*snapshot\|snapshot.*available"; then
        echo "snapshot_found"
    elif echo "$recent_logs" | grep -qi "Downloading.*snapshot\|snapshot.*download\|Applying.*snapshot"; then
        echo "downloading"
    elif echo "$recent_logs" | grep -qi "Restoring.*snapshot\|snapshot.*restore\|Verifying.*snapshot"; then
        echo "restoring"
    elif echo "$recent_logs" | grep -qi "state sync.*complete\|Switching to fastsync\|Switching to consensus"; then
        echo "completed"
    elif echo "$recent_logs" | grep -qi "state sync.*failed\|snapshot.*failed\|state sync.*error"; then
        echo "failed"
    else
        echo "unknown"
    fi
}

# Parse peer information from logs
get_peer_count() {
    local log_file="$HOME_DIR/logs/pchaind.log"
    [ ! -f "$log_file" ] && echo "0" && return
    
    # Try to extract peer count from recent logs
    local peer_info=$(tail -20 "$log_file" 2>/dev/null | grep -E "peers|numInPeers|numOutPeers" | tail -1 || echo "")
    if [ -n "$peer_info" ]; then
        # Extract numbers from peer information
        local in_peers=$(echo "$peer_info" | grep -o "numInPeers=[0-9]*" | cut -d'=' -f2 || echo "0")
        local out_peers=$(echo "$peer_info" | grep -o "numOutPeers=[0-9]*" | cut -d'=' -f2 || echo "0")
        local total_peers=$((in_peers + out_peers))
        echo "$total_peers"
    else
        echo "0"
    fi
}

# Extract snapshot progress information if available
get_snapshot_progress() {
    local log_file="$HOME_DIR/logs/pchaind.log"
    [ ! -f "$log_file" ] && return
    
    # Look for snapshot progress indicators in recent logs
    local progress_info=$(tail -30 "$log_file" 2>/dev/null | grep -E "snapshot.*progress|downloaded.*MB|restoring.*chunk" | tail -1 || echo "")
    
    if [ -n "$progress_info" ]; then
        # Try to extract progress percentage or size information
        local percentage=$(echo "$progress_info" | grep -o "[0-9]*%" | tail -1 | tr -d '%' || echo "")
        local mb_downloaded=$(echo "$progress_info" | grep -o "[0-9]*\.?[0-9]*\s*MB" | head -1 | tr -d 'MB ' || echo "")
        local mb_total=$(echo "$progress_info" | grep -o "of [0-9]*\.?[0-9]*\s*MB" | head -1 | tr -d 'ofMB ' || echo "")
        
        # Return structured data
        echo "percentage:${percentage:-0} downloaded:${mb_downloaded:-0} total:${mb_total:-0}"
    fi
}

# Check if state sync is actively progressing
is_state_sync_progressing() {
    local log_file="$HOME_DIR/logs/pchaind.log"
    [ ! -f "$log_file" ] && echo "false" && return
    
    # Check for recent activity (last 30 seconds worth of logs)
    local current_time=$(date +%s)
    local recent_activity=$(tail -10 "$log_file" 2>/dev/null | head -5 || echo "")
    
    # Look for signs of ongoing activity
    if echo "$recent_activity" | grep -qi "sync\|snapshot\|downloading\|restoring\|discovering"; then
        echo "true"
    else
        echo "false"
    fi
}

# Multi-phase state sync progress display
show_state_sync_progress() {
    local phase="$1"
    local elapsed_seconds="$2"
    local current_height="${3:-0}"
    local target_height="${4:-0}"
    
    case "$phase" in
        "starting")
            show_phase_progress "🚀 Initializing state sync" 1 4 10 "${BOLD}${WHITE}Preparing...${NC}"
            ;;
        "peer_discovery")
            local peers=$(get_peer_count)
            local elapsed_min=$((elapsed_seconds / 60))
            local elapsed_sec=$((elapsed_seconds % 60))
            show_peer_discovery_progress "$peers" 10 "$elapsed_seconds" 60
            ;;
        "snapshot_found")
            show_phase_progress "🎯 Snapshot located" 2 4 75 "${BOLD}${WHITE}Preparing download...${NC}"
            ;;
        "downloading")
            # Try to get snapshot progress info
            local progress_info=$(get_snapshot_progress)
            if [ -n "$progress_info" ]; then
                local downloaded=$(echo "$progress_info" | grep -o "downloaded:[0-9]*" | cut -d':' -f2 || echo "0")
                local total=$(echo "$progress_info" | grep -o "total:[0-9]*" | cut -d':' -f2 || echo "0")
                local percentage=$(echo "$progress_info" | grep -o "percentage:[0-9]*" | cut -d':' -f2 || echo "0")
                
                if [ "$total" -gt 0 ]; then
                    show_snapshot_progress "$downloaded" "$total" "0"
                else
                    show_phase_progress "📦 Downloading snapshot" 2 4 "$percentage" "${BOLD}${WHITE}Downloading...${NC}"
                fi
            else
                show_phase_progress "📦 Downloading snapshot" 2 4 50 "${BOLD}${WHITE}Downloading...${NC}"
            fi
            ;;
        "restoring")
            show_phase_progress "🔧 Applying snapshot" 3 4 85 "${BOLD}${WHITE}Restoring state...${NC}"
            ;;
        "completed")
            show_phase_progress "✅ State sync complete" 4 4 100 "${BOLD}${GREEN}Ready!${NC}"
            ;;
        "failed")
            show_phase_progress "❌ State sync failed" 4 4 0 "${BOLD}${RED}Failed${NC}"
            ;;
        *)
            # Calculate progress based on height if available, otherwise use time
            local sync_progress=0
            
            # If we have both current and target heights, calculate actual progress
            if [ "$current_height" -gt 0 ] && [ "$target_height" -gt 0 ]; then
                # For state sync, we typically jump from a low height to near the target
                # So we calculate progress as how close we are to the target
                if [ "$current_height" -ge "$target_height" ]; then
                    sync_progress="100"
                else
                    # Calculate how far we've progressed toward the target
                    sync_progress=$(echo "scale=1; 100 * $current_height / $target_height" | bc 2>/dev/null || echo "0")
                    # Ensure we show at least some progress if we have a height
                    [ "$current_height" -gt 0 ] && [ "$(echo "$sync_progress < 1" | bc 2>/dev/null || echo 0)" -eq 1 ] && sync_progress="1"
                fi
            elif [ "$elapsed_seconds" -gt 0 ]; then
                # Fallback to time-based progress if heights not available
                # Assume max 15 minutes for state sync
                sync_progress=$(echo "scale=1; 100 * $elapsed_seconds / 900" | bc 2>/dev/null || echo "0")
                [ "$(echo "$sync_progress > 100" | bc 2>/dev/null || echo 0)" -eq 1 ] && sync_progress="100"
            fi
            
            local elapsed_min=$((elapsed_seconds / 60))
            local elapsed_sec=$((elapsed_seconds % 60))
            local time_text="${BOLD}${WHITE}Time${NC} ${CYAN}${elapsed_min}m${elapsed_sec}s${NC}"
            
            if [ "$current_height" -gt 0 ]; then
                time_text="$time_text | ${BOLD}${WHITE}Height${NC} ${MAGENTA}${current_height}${NC}"
                if [ "$target_height" -gt 0 ]; then
                    time_text="$time_text/${MAGENTA}${target_height}${NC}"
                fi
            fi
            
            show_phase_progress "⏳ State sync in progress" 1 4 "$sync_progress" "$time_text"
            ;;
    esac
}

# Show comprehensive state sync status with all phases
show_complete_state_sync_status() {
    local sync_start_time="$1"
    local show_header="${2:-true}"
    
    if [ "$show_header" = "true" ]; then
        echo
        print_header "📡 State Sync Progress"
        echo
    fi
    
    # Get current status
    local current_time=$(date +%s)
    local elapsed=$((current_time - sync_start_time))
    local phase=$(detect_state_sync_phase)
    local is_progressing=$(is_state_sync_progressing)
    
    # Get node status for height information
    local node_status=$(curl -s localhost:26657/status 2>/dev/null || echo "")
    local current_height="0"
    local catching_up="true"
    
    if [ -n "$node_status" ]; then
        current_height=$(echo "$node_status" | jq -r '.result.sync_info.latest_block_height // "0"')
        catching_up=$(echo "$node_status" | jq -r '.result.sync_info.catching_up // true')
    fi
    
    # Try to get target height from network
    local target_height="0"
    if command -v curl >/dev/null 2>&1; then
        local network_status=$(curl -s --connect-timeout 3 https://rpc-testnet-donut-node2.push.org/status 2>/dev/null || echo "")
        if [ -n "$network_status" ]; then
            target_height=$(echo "$network_status" | jq -r '.result.sync_info.latest_block_height // "0"')
        fi
    fi
    
    # Show phase-specific progress
    show_state_sync_progress "$phase" "$elapsed" "$current_height" "$target_height"
    
    # Return status: 0 = completed, 1 = in progress, 2 = failed
    case "$phase" in
        "completed")
            if [ "$catching_up" = "false" ]; then
                return 0
            else
                return 1
            fi
            ;;
        "failed")
            return 2
            ;;
        *)
            return 1
            ;;
    esac
}

# Dependency helpers
require_cmd() {
    if ! command -v "$1" >/dev/null 2>&1; then
        echo "Missing dependency: $1" >&2
        exit 1
    fi
}

require_one_of() {
    for cmd in "$@"; do
        if command -v "$cmd" >/dev/null 2>&1; then
            return 0
        fi
    done
    echo "Missing dependency: one of [$*] is required" >&2
    exit 1
}

# Resolve hostname to single IPv4 address using dig/nslookup/host
resolve_host_ip() {
    local host="$1"
    local ip=""
    if command -v dig >/dev/null 2>&1; then
        ip=$(dig +short "$host" A | tail -n1)
    elif command -v nslookup >/dev/null 2>&1; then
        ip=$(nslookup "$host" 2>/dev/null | awk '/^Address: /{print $2; found=1} END{if(!found) exit 1}') || true
    elif command -v host >/dev/null 2>&1; then
        ip=$(host "$host" 2>/dev/null | awk '/ has address /{print $4; exit}') || true
    fi
    echo "$ip"
}

# Kill process listening on port if it is pchaind; try TERM then KILL
kill_pchaind_on_port() {
    local port="$1"
    local pids="$(lsof -tiTCP:"$port" -sTCP:LISTEN 2>/dev/null || true)"
    for pid in $pids; do
        if ps -o comm= -p "$pid" | grep -q "pchaind"; then
            kill "$pid" 2>/dev/null || true
            sleep 1
            if kill -0 "$pid" 2>/dev/null; then
                kill -9 "$pid" 2>/dev/null || true
            fi
        fi
    done
}

# Native binary path (prefer build/, fallback to scripts/build/)
BUILD_DIR="$SCRIPT_DIR/build"
SCRIPTS_BUILD_DIR="$SCRIPT_DIR/scripts/build"

resolve_binary_path() {
    if [ -f "$BUILD_DIR/pchaind" ]; then
        PCHAIND="$BUILD_DIR/pchaind"
    elif [ -f "$SCRIPTS_BUILD_DIR/pchaind" ]; then
        PCHAIND="$SCRIPTS_BUILD_DIR/pchaind"
    else
        PCHAIND="$BUILD_DIR/pchaind" # default
    fi
}

resolve_binary_path

# Check if binary exists and auto-setup if missing
if [ ! -f "$PCHAIND" ]; then
    print_warning "❌ Native binary not found at: $PCHAIND"
    print_status "🔧 Running automatic dependency setup and build..."
    echo
    
    # Run setup script automatically
    if [ -f "$SCRIPT_DIR/scripts/setup-dependencies.sh" ]; then
        bash "$SCRIPT_DIR/scripts/setup-dependencies.sh"
        echo
        print_success "✅ Auto-setup completed! Continuing with node start..."
        echo
        # Ensure convenience symlink exists
        mkdir -p "$BUILD_DIR" 2>/dev/null || true
        if [ -f "$SCRIPTS_BUILD_DIR/pchaind" ] && [ ! -f "$BUILD_DIR/pchaind" ]; then
            ln -sf "../scripts/build/pchaind" "$BUILD_DIR/pchaind" 2>/dev/null || true
        fi
        # Re-resolve binary path after setup
        resolve_binary_path
    else
        print_error "❌ Setup script not found: $SCRIPT_DIR/scripts/setup-dependencies.sh"
        exit 1
    fi
    
    # Verify binary was created
    if [ ! -f "$PCHAIND" ]; then
        print_error "❌ Binary creation failed during auto-setup"
        exit 1
    fi
fi

# Verify critical dependencies up front
require_cmd curl
require_cmd jq
require_cmd awk
require_cmd sed
require_cmd bc
require_cmd lsof
require_cmd nohup
require_one_of dig nslookup host

# Fast, resilient HTTP getter with short timeouts
http_get_quick() {
    # Usage: http_get_quick <url> [max_time_seconds]
    local url="$1"
    local max_time="${2:-3}"
    curl -fsS --connect-timeout 1 --max-time "$max_time" "$url" 2>/dev/null || echo ""
}

# ASCII Art Banner
show_banner() {
    echo -e "${BOLD}${GREEN}"
    echo "    ____             __       ________          _      "
    echo "   / __ \\__  _______/ /_     / ____/ /_  ____ _(_)___  "
    echo "  / /_/ / / / / ___/ __ \\   / /   / __ \\/ __ \`/ / __ \\ "
    echo " / ____/ /_/ (__  ) / / /  / /___/ / / / /_/ / / / / / "
    echo "/_/    \\__,_/____/_/ /_/   \\____/_/ /_/\\__,_/_/_/ /_/  "
    echo -e "${NC}"
    echo -e "${BOLD}${YELLOW}            Push Validator Manager${NC}"
    echo -e "${GREEN}        ═══════════════════════════════${NC}"
    echo
}

# Chain configuration
CHAIN_ID="push_42101-1"
MONIKER="${MONIKER:-push-validator}"
DENOM="upc"
HOME_DIR="$HOME/.pchain"
GENESIS_DOMAIN="${GENESIS_DOMAIN:-rpc-testnet-donut-node1.push.org}"
GENESIS_RPC="https://$GENESIS_DOMAIN"
KEYRING_BACKEND="${KEYRING_BACKEND:-test}"

# Binary path already set by resolve_binary_path function above

# Process management
PCHAIND_PID_FILE="$HOME_DIR/pchaind.pid"

# Automatic Snapshot Recovery Configuration
AUTO_RECOVERY_ENABLED="${AUTO_RECOVERY_ENABLED:-true}"
SYNC_STALL_THRESHOLD="${SYNC_STALL_THRESHOLD:-120}"  # seconds before triggering recovery
MAX_RECOVERY_ATTEMPTS="${MAX_RECOVERY_ATTEMPTS:-3}"
RECOVERY_BACKOFF="${RECOVERY_BACKOFF:-300}"  # 5 minutes between attempts

# RPC Configuration for State Sync
# IMPORTANT: Only rpc-testnet-donut-node2.push.org has snapshots available
# Other nodes (node1, etc.) are for P2P connectivity but don't provide snapshots
# TODO: When additional snapshot-enabled RPC nodes become available, update to use distinct primary/secondary
SNAPSHOT_RPC="${SNAPSHOT_RPC:-https://rpc-testnet-donut-node2.push.org}"
SNAPSHOT_RPC_PRIMARY="${SNAPSHOT_RPC_PRIMARY:-$SNAPSHOT_RPC}"
SNAPSHOT_RPC_SECONDARY="${SNAPSHOT_RPC_SECONDARY:-$SNAPSHOT_RPC_PRIMARY}"  # Fallback to primary until second RPC available

BACKUP_BEFORE_RECOVERY="${BACKUP_BEFORE_RECOVERY:-true}"

# Recovery tracking variables
last_height_change_time=$(date +%s)
recovery_attempts=0
last_recovery_time=0
previous_sync_height=0

# Check if node is running
is_node_running() {
    # Check PID file
    if [ -f "$PCHAIND_PID_FILE" ]; then
        PID=$(cat "$PCHAIND_PID_FILE")
        if ps -p "$PID" > /dev/null 2>&1; then
            # Verify it's actually pchaind process
            if ps -p "$PID" -o comm= | grep -q "pchaind"; then
                return 0
            fi
        fi
        # PID file exists but process not found or wrong process - clean up
        rm -f "$PCHAIND_PID_FILE" 2>/dev/null || true
    fi
    
    # Fallback: check if pchaind is running and listening on expected port
    if pgrep -f "pchaind.*start.*--home.*$HOME_DIR" > /dev/null 2>&1; then
        # Found process, update PID file
        local FOUND_PID=$(pgrep -f "pchaind.*start.*--home.*$HOME_DIR" | head -1)
        echo "$FOUND_PID" > "$PCHAIND_PID_FILE"
        return 0
    fi
    
    return 1
}

# Start node in background
start_node() {
    echo  # Add blank line for spacing
    print_status "🚀 Starting Push Chain node..."
    
    # Ensure logs directory exists
    mkdir -p "$HOME_DIR/logs"
    
    # If already running, do not disturb the running process
    if is_node_running; then
        if [ -f "$PCHAIND_PID_FILE" ]; then
            PID=$(cat "$PCHAIND_PID_FILE" 2>/dev/null)
            print_success "✅ Node already running (PID: $PID)"
        else
            print_success "✅ Node already running"
        fi
        print_status "Use: ${BOLD}push-validator-manager sync${NC} to monitor or ${BOLD}push-validator-manager status${NC}"
        return 0
    fi
    
    # Comprehensive cleanup of port conflicts and stale processes (silent)
    
    # Kill only pchaind processes bound to the known ports
    kill_pchaind_on_port 26657
    kill_pchaind_on_port 26656
    
    # Remove stale PID file
    rm -f "$PCHAIND_PID_FILE" 2>/dev/null || true
    
    # Brief pause to ensure cleanup
    sleep 1
    
    # Check for missing genesis.json and restore if needed
    if [ ! -f "$HOME_DIR/config/genesis.json" ] || [ ! -s "$HOME_DIR/config/genesis.json" ]; then
        print_status "🔧 Genesis file missing or empty, restoring..."
        mkdir -p "$HOME_DIR/config"
        GENESIS_DATA=$(curl -fsS --connect-timeout 5 --max-time 30 "$GENESIS_RPC/genesis" 2>/dev/null)
        if [ -n "$GENESIS_DATA" ]; then
            echo "$GENESIS_DATA" | jq -r '.result.genesis' > "$HOME_DIR/config/genesis.json"
            if [ -s "$HOME_DIR/config/genesis.json" ] && jq -e '.chain_id' "$HOME_DIR/config/genesis.json" >/dev/null 2>&1; then
                print_success "✅ Genesis configuration restored"
            else
                print_error "❌ Failed to restore genesis - check network connection"
                exit 1
            fi
        else
            print_error "❌ Failed to fetch genesis from $GENESIS_RPC"
            exit 1
        fi
    fi
    
    # Initialize if needed
    if [ ! -f "$HOME_DIR/config/config.toml" ]; then
        print_status "🧱 Initializing validator node: $MONIKER ($CHAIN_ID)"
        mkdir -p "$HOME_DIR/config" "$HOME_DIR/logs"
        
        # Initialize the chain with overwrite flag since we may have restored genesis.json already
        "$PCHAIND" init "$MONIKER" --chain-id "$CHAIN_ID" --default-denom "$DENOM" --home "$HOME_DIR" --overwrite >/dev/null 2>&1
        if [ $? -ne 0 ]; then
            print_error "❌ Initialization failed"
            exit 1
        fi
        
        # For validators, we'll use state sync instead of syncing from genesis
        print_status "🚀 Validator mode: Will use state sync for quick initialization"
        
        # We still need genesis for chain config, but not for syncing
        print_status "⚙️ Fetching chain configuration from $GENESIS_RPC"
        # Use longer timeout for genesis as it can be large
        GENESIS_DATA=$(curl -fsS --connect-timeout 5 --max-time 30 "$GENESIS_RPC/genesis" 2>/dev/null)
        if [ -z "$GENESIS_DATA" ]; then
            print_error "❌ Failed to fetch genesis from $GENESIS_RPC"
            exit 1
        fi
        
        # Extract and save genesis
        echo "$GENESIS_DATA" | jq -r '.result.genesis' > "$HOME_DIR/config/genesis.json"
        
        # Verify genesis was saved correctly
        if [ ! -s "$HOME_DIR/config/genesis.json" ] || ! jq -e '.chain_id' "$HOME_DIR/config/genesis.json" >/dev/null 2>&1; then
            print_error "❌ Invalid or empty genesis file"
            exit 1
        fi
        
        # Get peers for P2P network
        print_status "🔍 Fetching network peers"
        PEERS_JSON=$(http_get_quick "$GENESIS_RPC/net_info" 3)
        [ -n "$PEERS_JSON" ] || PEERS_JSON='{}'
        PERSISTENT_PEERS=""
        
        if [ -n "$PEERS_JSON" ] && [ "$PEERS_JSON" != '{}' ]; then
            # Filter out peers with misconfigured listen_addr (0.0.0.0) and get only properly configured peers
            PEER_LIST=$(echo "$PEERS_JSON" | jq -r '.result.peers[]? | select(.node_info.listen_addr | contains("0.0.0.0") | not) | "\(.node_info.id)@\(.remote_ip):26656"' 2>/dev/null | head -3 || true)
            if [ -n "$PEER_LIST" ]; then
                PERSISTENT_PEERS=$(echo "$PEER_LIST" | tr '\n' ',' | sed 's/,$//')
                print_status "✅ Found $(echo "$PEER_LIST" | wc -l | tr -d ' ') properly configured peers"
            else
                print_status "⚠️ No properly configured peers found, using fallback"
            fi
        fi
        
        if [ -z "$PERSISTENT_PEERS" ]; then
            # Fallback to known testnet nodes
            # IMPORTANT: node2 has snapshots, both nodes provide P2P connectivity
            print_status "🔗 Configuring known testnet peers..."
            NODE1_ID=$(curl -s https://rpc-testnet-donut-node1.push.org/status 2>/dev/null | jq -r '.result.node_info.id // empty')
            NODE2_ID=$(curl -s https://rpc-testnet-donut-node2.push.org/status 2>/dev/null | jq -r '.result.node_info.id // empty')
            
            PEERS_LIST=""
            if [ -n "$NODE1_ID" ] && [ "$NODE1_ID" != "null" ]; then
                PEERS_LIST="${NODE1_ID}@rpc-testnet-donut-node1.push.org:26656"
            fi
            if [ -n "$NODE2_ID" ] && [ "$NODE2_ID" != "null" ]; then
                if [ -n "$PEERS_LIST" ]; then
                    PEERS_LIST="${PEERS_LIST},${NODE2_ID}@rpc-testnet-donut-node2.push.org:26656"
                else
                    PEERS_LIST="${NODE2_ID}@rpc-testnet-donut-node2.push.org:26656"
                fi
            fi
            
            if [ -n "$PEERS_LIST" ]; then
                PERSISTENT_PEERS="$PEERS_LIST"
                print_status "✅ Configured testnet peers"
            else
                print_warning "⚠️ Could not fetch peer IDs, node may have connection issues"
            fi
        fi
        
        if [ -n "$PERSISTENT_PEERS" ]; then
            sed -i.bak \
                -e "s/^persistent_peers = .*/persistent_peers = \"$PERSISTENT_PEERS\"/" \
                -e "s/^addr_book_strict = .*/addr_book_strict = false/" \
                "$HOME_DIR/config/config.toml"
        fi
        
        # Configure pruning for validator (keep minimal history)
        print_status "⚙️ Configuring validator pruning settings"
        sed -i.bak \
            -e 's/^pruning = .*/pruning = "default"/' \
            -e 's/^pruning-keep-recent = .*/pruning-keep-recent = "100"/' \
            -e 's/^pruning-interval = .*/pruning-interval = "10"/' \
            "$HOME_DIR/config/app.toml" 2>/dev/null || true
        
        # Mark for state sync on first start
        touch "$HOME_DIR/.needs_state_sync"
        
        print_success "✅ Validator node configured"
    fi
    
    # Check if this is first start or recovery needed
    if [ -f "$HOME_DIR/.needs_state_sync" ] || [ ! -d "$HOME_DIR/data/blockstore.db" ]; then
        print_header "🔄 Configuring State Sync"
        
        # Configure and perform state sync
        if configure_state_sync "$SNAPSHOT_RPC"; then
            # Remove the flag file
            rm -f "$HOME_DIR/.needs_state_sync"
            
            # Reset any partial data
            if [ -d "$HOME_DIR/data" ]; then
                print_status "🗑️ Clearing partial blockchain data..."
                $PCHAIND tendermint unsafe-reset-all --home "$HOME_DIR" --keep-addr-book 2>/dev/null || true
            fi
            
            print_status "📡 Starting with state sync enabled..."
            
            # Mark that we're doing initial state sync
            touch "$HOME_DIR/.initial_state_sync"
            
            # State sync will happen automatically when node starts
        else
            print_error "❌ Failed to configure state sync"
            print_status "Falling back to normal sync (this will take longer)"
            # Remove state sync config if it failed
            sed -i.bak -e '/^\[statesync\]/,/^\[/{s/^enable = .*/enable = false/}' "$HOME_DIR/config/config.toml"
        fi
    fi
    
    # Ensure priv_validator_state.json exists to avoid CometBFT panic when data was wiped
    if [ ! -f "$HOME_DIR/data/priv_validator_state.json" ]; then
        mkdir -p "$HOME_DIR/data"
        cat > "$HOME_DIR/data/priv_validator_state.json" <<'STATEEOF'
{
  "height": "0",
  "round": 0,
  "step": 0
}
STATEEOF
    fi
    
    # Start in background with proper signal isolation
    mkdir -p "$HOME_DIR/logs"
    
    # Use daemon launcher to create a truly detached process
    SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    DAEMON_LAUNCHER="$SCRIPT_DIR/daemon-launcher.sh"
    
    if [[ -f "$DAEMON_LAUNCHER" ]]; then
        # Use the daemon launcher for complete detachment
        "$DAEMON_LAUNCHER" "$PCHAIND" "$HOME_DIR" "$PCHAIND_PID_FILE" "$HOME_DIR/logs/pchaind.log"
        
        # Wait for PID file to be created
        local wait_count=0
        while [[ ! -f "$PCHAIND_PID_FILE" ]] && [[ $wait_count -lt 10 ]]; do
            sleep 0.1
            ((wait_count++))
        done
        
        if [[ -f "$PCHAIND_PID_FILE" ]]; then
            PID=$(cat "$PCHAIND_PID_FILE")
        else
            print_error "❌ Failed to create PID file"
            return 1
        fi
    else
        # Fallback to previous method if launcher script not found
        (
            trap '' INT TERM HUP
            nohup "$PCHAIND" start --home "$HOME_DIR" > "$HOME_DIR/logs/pchaind.log" 2>&1 < /dev/null &
            echo $! > "$PCHAIND_PID_FILE"
        ) &
        
        # Wait for PID file to be written
        sleep 0.5
        
        # Read the actual PID
        if [ -f "$PCHAIND_PID_FILE" ]; then
            PID=$(cat "$PCHAIND_PID_FILE")
        else
            # Fallback: find the process
            PID=$(pgrep -f "pchaind.*start.*--home.*$HOME_DIR" | head -1)
        fi
        echo $PID > "$PCHAIND_PID_FILE"
    fi
    
    # Wait a moment and verify the process actually started
    sleep 1
    if ! kill -0 "$PID" 2>/dev/null; then
        print_error "❌ Node failed to start - process exited immediately"
        if [ -f "$HOME_DIR/logs/pchaind.log" ]; then
            print_warning "Last log entries:"
            tail -20 "$HOME_DIR/logs/pchaind.log"
        fi
        rm -f "$PCHAIND_PID_FILE"
        return 1
    fi
    
    print_success "✅ Node started successfully"
    
    # Show sync status (safe - won't kill node on Ctrl+C)
    show_sync_after_start
}

# Safe sync monitoring that doesn't kill the node on Ctrl+C
show_sync_after_start() {
    # Skip monitoring if called from installer
    if [ "${SKIP_SYNC_MONITOR:-}" = "true" ]; then
        return 0
    fi
    
    # Check if this is initial state sync
    if [ -f "$HOME_DIR/.initial_state_sync" ]; then
        print_header "📡 State Sync Progress"
        
        # Monitor state sync progress
        if monitor_state_sync; then
            # State sync completed successfully
            rm -f "$HOME_DIR/.initial_state_sync"
            
            # Disable state sync for future restarts
            sed -i.bak -e '/^\[statesync\]/,/^\[/{s/^enable = .*/enable = false/}' "$HOME_DIR/config/config.toml"
            
            print_success "✅ Validator is now fully synced and ready!"
            echo
            print_status "You can now register as a validator:"
            echo "  ${BOLD}push-validator-manager register-validator${NC}"
        else
            print_warning "⚠️ State sync monitoring stopped"
        fi
    else
        # Run normal sync monitor in a subshell
        (
            # Give node a moment to initialize
            sleep 3
            # Start monitoring (prefer WebSocket, fallback to polling)
            monitor_sync_auto --compact
        )
    fi
    # Return 0 so the parent script continues normally
    return 0
}

# Stop node
stop_node() {
    echo  # Add blank line for spacing
    print_status "🛑 Stopping Push Chain node..."
    
    if is_node_running; then
        PID=$(cat "$PCHAIND_PID_FILE")
        kill "$PID" 2>/dev/null || true
        # wait up to 5s
        for i in {1..5}; do
            if ! kill -0 "$PID" 2>/dev/null; then
                break
            fi
            sleep 1
        done
        if kill -0 "$PID" 2>/dev/null; then
            kill -9 "$PID" 2>/dev/null || true
        fi
        rm -f "$PCHAIND_PID_FILE" 2>/dev/null || true
        print_success "✅ Node stop signal sent (PID: $PID)"
        # Extra safety: ensure no stray pchaind still listens on known ports
        kill_pchaind_on_port 26657
        kill_pchaind_on_port 26656
        # Brief wait and verify
        sleep 1
        if lsof -tiTCP:26657 -sTCP:LISTEN 2>/dev/null | xargs -I{} ps -o comm= -p {} 2>/dev/null | grep -q "pchaind"; then
            print_warning "⚠️ pchaind still detected on 26657; forcing termination"
            kill_pchaind_on_port 26657
        fi
        if lsof -tiTCP:26656 -sTCP:LISTEN 2>/dev/null | xargs -I{} ps -o comm= -p {} 2>/dev/null | grep -q "pchaind"; then
            print_warning "⚠️ pchaind still detected on 26656; forcing termination"
            kill_pchaind_on_port 26656
        fi
        print_success "✅ Node stopped"
    else
        print_warning "⚠️ Node is not running"
    fi
}

# Show node status
show_status() {
    echo  # Add blank line for spacing
    print_header "📊 Push Chain Node Status"
    echo -e "${GREEN}══════════════════════════════════════════${NC}"
    
    echo -e "${BOLD}${BLUE}Runtime Mode: ${GREEN}Native Execution${NC}"
    echo -e "  ${BOLD}Binary:${NC} $PCHAIND"
    # Get version safely with better error handling
    if [ -f "$PCHAIND" ]; then
        VERSION=$("$PCHAIND" version 2>&1 | grep -v "WARNING" | head -n1 || echo "v1.0.1-native")
        # Fallback if version command doesn't work
        if [ -z "$VERSION" ] || [ "$VERSION" = "" ]; then
            VERSION="v1.0.1-native"
        fi
    else
        VERSION="Binary not found"
    fi
    echo -e "  ${BOLD}Version:${NC} $VERSION"
    echo
    
    if [ -f "$HOME_DIR/config/config.toml" ]; then
        print_success "✅ Node initialized"
        
        if is_node_running; then
            if [ -f "$PCHAIND_PID_FILE" ]; then
                PID=$(cat "$PCHAIND_PID_FILE" 2>/dev/null)
                print_success "✅ Node is running (PID: $PID)"
            else
                print_success "✅ Node is running"
            fi
            
            # Get detailed status
            if command -v curl >/dev/null 2>&1 && command -v jq >/dev/null 2>&1; then
                NODE_STATUS=$(http_get_quick http://localhost:26657/status 2)
                
                if [ -n "$NODE_STATUS" ]; then
                    echo
                    print_header "Node Information:"
                    echo -e "${GREEN}─────────────────────────────────────────${NC}"
                    
                    NODE_ID=$(echo "$NODE_STATUS" | jq -r '.result.node_info.id // "unknown"' 2>/dev/null)
                    NETWORK=$(echo "$NODE_STATUS" | jq -r '.result.node_info.network // "unknown"' 2>/dev/null)  
                    MONIKER=$(echo "$NODE_STATUS" | jq -r '.result.node_info.moniker // "unknown"' 2>/dev/null)
                    
                    echo -e "  ${BOLD}Node ID:${NC} ${MAGENTA}$NODE_ID${NC}"
                    echo -e "  ${BOLD}Network:${NC} ${GREEN}$NETWORK${NC}"
                    echo -e "  ${BOLD}Moniker:${NC} ${BOLD}${WHITE}$MONIKER${NC}"
                    
                    echo
                    print_header "Sync Status:"
                    echo -e "${GREEN}─────────────────────────────────────────${NC}"
                    
                    LOCAL_HEIGHT=$(echo "$NODE_STATUS" | jq -r '.result.sync_info.latest_block_height // "0"' 2>/dev/null)
                    LATEST_TIME=$(echo "$NODE_STATUS" | jq -r '.result.sync_info.latest_block_time // "unknown"' 2>/dev/null)
                    CATCHING_UP=$(echo "$NODE_STATUS" | jq -r '.result.sync_info.catching_up // "true"' 2>/dev/null)
                    
                    # Fetch remote network height to determine actual sync status
                    REMOTE_HEIGHT=0
                    REMOTE_STATUS=$(http_get_quick "$GENESIS_RPC/status" 3)
                    if [ -n "$REMOTE_STATUS" ]; then
                        REMOTE_HEIGHT=$(echo "$REMOTE_STATUS" | jq -r '.result.sync_info.latest_block_height // "0"' 2>/dev/null || echo "0")
                    fi
                    
                    # Normalize to integers
                    [[ "$LOCAL_HEIGHT" =~ ^[0-9]+$ ]] || LOCAL_HEIGHT=0
                    [[ "$REMOTE_HEIGHT" =~ ^[0-9]+$ ]] || REMOTE_HEIGHT=0
                    
                    # Display block height with network comparison if available
                    if [ "$REMOTE_HEIGHT" -gt 0 ]; then
                        echo -e "  ${BOLD}Block Height:${NC} ${MAGENTA}$LOCAL_HEIGHT${NC} / ${MAGENTA}$REMOTE_HEIGHT${NC} (network)"
                    else
                        echo -e "  ${BOLD}Block Height:${NC} ${MAGENTA}$LOCAL_HEIGHT${NC}"
                    fi
                    echo -e "  ${BOLD}Block Time:${NC} $LATEST_TIME"
                    
                    # Determine actual sync status based on height comparison
                    if [ "$REMOTE_HEIGHT" -gt 0 ]; then
                        HEIGHT_DIFF=$((REMOTE_HEIGHT - LOCAL_HEIGHT))
                        
                        if [ "$HEIGHT_DIFF" -le 5 ]; then
                            # Within 5 blocks of network height - considered synced
                            echo -e "  ${BOLD}Status:${NC} ${GREEN}✅ Fully Synced${NC}"
                        elif [ "$HEIGHT_DIFF" -gt 5 ] && [ "$HEIGHT_DIFF" -le 100 ]; then
                            # Slightly behind but catching up
                            PROGRESS_PERCENT=$(echo "scale=2; 100 * $LOCAL_HEIGHT / $REMOTE_HEIGHT" | bc 2>/dev/null || echo "99")
                            echo -e "  ${BOLD}Status:${NC} ${YELLOW}🔄 Syncing new blocks${NC} (${GREEN}${PROGRESS_PERCENT}%${NC})"
                        else
                            # Significantly behind - show progress
                            PROGRESS_PERCENT=$(echo "scale=2; 100 * $LOCAL_HEIGHT / $REMOTE_HEIGHT" | bc 2>/dev/null || echo "0")
                            REMAINING_BLOCKS=$HEIGHT_DIFF
                            echo -e "  ${BOLD}Status:${NC} ${YELLOW}⏳ Syncing...${NC} (${GREEN}${PROGRESS_PERCENT}%${NC} - ${REMAINING_BLOCKS} blocks behind)"
                        fi
                    else
                        # Fallback to original logic if can't fetch remote height
                        if [ "$CATCHING_UP" = "false" ]; then
                            echo -e "  ${BOLD}Status:${NC} ${GREEN}✅ Fully Synced${NC}"
                        else
                            echo -e "  ${BOLD}Status:${NC} ${YELLOW}⏳ Syncing...${NC}"
                        fi
                    fi
                else
                    print_warning "⚠️ Node is starting up..."
                fi
            else
                print_warning "⚠️ curl or jq not available - install for detailed status"
            fi
        else
            print_error "❌ Node is not running"
            echo "Use: push-validator-manager start"
        fi
    else
        print_error "❌ Node not initialized"
        echo "Use: push-validator-manager start"
    fi
}

# Backup node data before recovery
backup_node_data() {
    local timestamp=$(date +"%Y%m%d_%H%M%S")
    local backup_dir="$HOME/push-node-backups"
    local backup_file="$backup_dir/pchain_recovery_backup_${timestamp}.tar.gz"
    
    print_status "📦 Creating backup before recovery..."
    mkdir -p "$backup_dir"
    
    # Backup critical data (exclude large blockchain data)
    tar -czf "$backup_file" \
        --exclude="$HOME_DIR/data/application.db" \
        --exclude="$HOME_DIR/data/blockstore.db" \
        --exclude="$HOME_DIR/data/cs.wal" \
        --exclude="$HOME_DIR/data/evidence.db" \
        --exclude="$HOME_DIR/data/state.db" \
        --exclude="$HOME_DIR/data/tx_index.db" \
        "$HOME_DIR/config" \
        "$HOME_DIR/data/priv_validator_state.json" \
        2>/dev/null || true
    
    if [ -f "$backup_file" ]; then
        print_success "✅ Backup created: $backup_file"
        echo "$backup_file"
    else
        print_warning "⚠️ Backup creation failed"
        echo ""
    fi
}

# Wait for node sync to complete with progress monitoring
# Returns 0 if sync completes, 1 if timeout or error
wait_for_sync_completion() {
    local MAX_WAIT="${1:-600}"  # Default 10 minutes timeout
    local SHOW_PROGRESS="${2:-true}"  # Show progress by default
    
    local SYNC_COMPLETE=false
    local WAIT_TIME=0
    local sync_start_time=$(date +%s)
    
    print_status "⏳ Waiting for node to sync..."
    
    while [ $WAIT_TIME -lt $MAX_WAIT ]; do
        # Check if node is still running
        if ! is_node_running; then
            print_error "❌ Node stopped during sync"
            return 1
        fi
        
        # Get sync status from RPC
        local status=$(curl -s localhost:26657/status 2>/dev/null)
        
        if [ -n "$status" ]; then
            local catching_up=$(echo "$status" | jq -r '.result.sync_info.catching_up // true')
            local current_height=$(echo "$status" | jq -r '.result.sync_info.latest_block_height // "0"')
            local network_height=$(echo "$status" | jq -r '.result.sync_info.earliest_block_height // "0"' 2>/dev/null)
            
            # Try to get network height from peers if not available
            if [ "$network_height" = "0" ] || [ "$network_height" = "null" ]; then
                # Get from net_info for a better estimate
                local net_info=$(curl -s localhost:26657/net_info 2>/dev/null)
                if [ -n "$net_info" ]; then
                    # This is an approximation - get the highest peer height
                    network_height=$(echo "$net_info" | jq -r '[.result.peers[].connection_status.SendMonitor.Start // 0] | max // 0' 2>/dev/null)
                fi
            fi
            
            # Check if fully synced
            if [ "$catching_up" = "false" ] && [ "$current_height" != "0" ] && [ "$current_height" != "null" ]; then
                SYNC_COMPLETE=true
                if [ "$SHOW_PROGRESS" = "true" ]; then
                    echo  # New line after progress
                    print_success "✅ Node is fully synced at height $current_height!"
                fi
                break
            fi
            
            # Show progress if enabled and we have valid heights
            if [ "$SHOW_PROGRESS" = "true" ] && [ "$current_height" != "0" ] && [ "$current_height" != "null" ]; then
                if [ "$network_height" != "0" ] && [ "$network_height" != "null" ] && [ $network_height -gt 0 ]; then
                    local PERCENT=$((current_height * 100 / network_height))
                    [ $PERCENT -gt 100 ] && PERCENT=100
                    echo -ne "\r\033[K🔄 Syncing: ${current_height}/${network_height} (${PERCENT}%)  "
                else
                    echo -ne "\r\033[K🔄 Syncing: Block height ${current_height}  "
                fi
            fi
        fi
        
        sleep 3
        WAIT_TIME=$((WAIT_TIME + 3))
    done
    
    if [ "$SYNC_COMPLETE" = true ]; then
        return 0
    else
        if [ "$SHOW_PROGRESS" = "true" ]; then
            echo  # New line after progress
            print_warning "⚠️ Sync timeout after ${MAX_WAIT} seconds"
        fi
        return 1
    fi
}

# Configure state sync in config.toml
configure_state_sync() {
    local rpc_server="${1:-$SNAPSHOT_RPC}"
    
    # Strip protocol from RPC URLs for state sync (expects host:port format)
    local rpc_primary_host=$(echo "$SNAPSHOT_RPC_PRIMARY" | sed 's|^https://||' | sed 's|^http://||')
    local rpc_secondary_host=$(echo "$SNAPSHOT_RPC_SECONDARY" | sed 's|^https://||' | sed 's|^http://||')
    
    # Configure RPC servers - using primary and secondary (may be identical if only one available)
    # State sync needs full URLs with https protocol
    local rpc_servers="https://${rpc_primary_host}:443,https://${rpc_secondary_host}:443"

    print_status "🔧 Configuring state sync from $rpc_server..."

    # Get latest block info from RPC (keep protocol for curl)
    local latest_block=$(curl -s "$rpc_server/block" | jq -r '.result.block.header.height // empty' 2>/dev/null)
    if [ -z "$latest_block" ] || [ "$latest_block" = "null" ]; then
        print_error "❌ Failed to get latest block from RPC"
        return 1
    fi
    
    # Calculate trust height (1000 blocks behind latest for safety)
    local trust_height=$((latest_block - 1000))
    if [ $trust_height -lt 1 ]; then
        trust_height=1
    fi
    
    # Get trust hash
    local trust_hash=$(curl -s "$rpc_server/block?height=$trust_height" | jq -r '.result.block_id.hash // empty' 2>/dev/null)
    if [ -z "$trust_hash" ] || [ "$trust_hash" = "null" ]; then
        print_error "❌ Failed to get trust hash from RPC"
        return 1
    fi
    
    print_status "📊 Configuring state sync with:"
    echo "  Trust Height: $trust_height"
    echo "  Trust Hash: $trust_hash"
    echo "  RPC Servers: $rpc_servers"
    
    # Update config.toml with state sync settings
    local config_file="$HOME_DIR/config/config.toml"
    
    # Backup original config
    cp "$config_file" "$config_file.backup"
    
    # Configure persistent peers for state sync
    # IMPORTANT: State sync requires peers to discover snapshots
    print_status "🔗 Configuring peers for state sync..."
    NODE1_ID=$(curl -s https://rpc-testnet-donut-node1.push.org/status 2>/dev/null | jq -r '.result.node_info.id // empty')
    NODE2_ID=$(curl -s https://rpc-testnet-donut-node2.push.org/status 2>/dev/null | jq -r '.result.node_info.id // empty')
    
    PEERS_LIST=""
    if [ -n "$NODE1_ID" ] && [ "$NODE1_ID" != "null" ]; then
        PEERS_LIST="${NODE1_ID}@rpc-testnet-donut-node1.push.org:26656"
    fi
    if [ -n "$NODE2_ID" ] && [ "$NODE2_ID" != "null" ]; then
        if [ -n "$PEERS_LIST" ]; then
            PEERS_LIST="${PEERS_LIST},${NODE2_ID}@rpc-testnet-donut-node2.push.org:26656"
        else
            PEERS_LIST="${NODE2_ID}@rpc-testnet-donut-node2.push.org:26656"
        fi
    fi
    
    # Enable state sync and set parameters including peers
    sed -i.tmp \
        -e '/^\[statesync\]/,/^\[/{' \
        -e 's/^enable = .*/enable = true/' \
        -e 's|^rpc_servers = .*|rpc_servers = "'"$rpc_servers"'"|' \
        -e 's/^trust_height = .*/trust_height = '"$trust_height"'/' \
        -e 's/^trust_hash = .*/trust_hash = "'"$trust_hash"'"/' \
        -e 's/^trust_period = .*/trust_period = "336h0m0s"/' \
        -e '}' \
        -e "s/^persistent_peers = .*/persistent_peers = \"$PEERS_LIST\"/" \
        -e "s/^addr_book_strict = .*/addr_book_strict = false/" \
        "$config_file"
    
    print_success "✅ State sync configured"
    return 0
}

# Perform snapshot recovery
recover_from_snapshot() {
    local reason="${1:-sync stall detected}"
    
    print_header "🔄 Initiating Snapshot Recovery"
    echo -e "${YELLOW}Reason: $reason${NC}"
    echo
    
    # Check if auto recovery is enabled
    if [ "$AUTO_RECOVERY_ENABLED" != "true" ]; then
        print_warning "⚠️ Automatic recovery is disabled"
        echo "Enable with: export AUTO_RECOVERY_ENABLED=true"
        return 1
    fi
    
    # Check recovery attempts
    local current_time=$(date +%s)
    if [ $recovery_attempts -ge $MAX_RECOVERY_ATTEMPTS ]; then
        print_error "❌ Maximum recovery attempts ($MAX_RECOVERY_ATTEMPTS) reached"
        echo "Manual intervention required. Reset with: export recovery_attempts=0"
        return 1
    fi
    
    # Check backoff period
    local time_since_last=$((current_time - last_recovery_time))
    if [ $time_since_last -lt $RECOVERY_BACKOFF ] && [ $last_recovery_time -gt 0 ]; then
        local wait_time=$((RECOVERY_BACKOFF - time_since_last))
        print_warning "⚠️ Recovery backoff period active"
        echo "Wait $wait_time seconds before next attempt"
        return 1
    fi
    
    # Increment recovery attempts
    recovery_attempts=$((recovery_attempts + 1))
    last_recovery_time=$current_time
    
    print_status "🔄 Recovery attempt $recovery_attempts of $MAX_RECOVERY_ATTEMPTS"
    
    # Step 1: Create backup
    if [ "$BACKUP_BEFORE_RECOVERY" = "true" ]; then
        backup_file=$(backup_node_data)
    fi
    
    # Step 2: Stop the node
    print_status "⏹️ Stopping node..."
    stop_node
    sleep 2
    
    # Step 3: Configure state sync
    if ! configure_state_sync "$SNAPSHOT_RPC"; then
        print_error "❌ Failed to configure state sync"
        # Restore backup config
        if [ -f "$HOME_DIR/config/config.toml.backup" ]; then
            mv "$HOME_DIR/config/config.toml.backup" "$HOME_DIR/config/config.toml"
        fi
        start_node
        return 1
    fi
    
    # Step 4: Reset blockchain data (keep address book and keys)
    print_status "🗑️ Resetting blockchain data..."
    $PCHAIND tendermint unsafe-reset-all --home "$HOME_DIR" --keep-addr-book 2>/dev/null || {
        print_error "❌ Failed to reset blockchain data"
        # Restore backup config
        if [ -f "$HOME_DIR/config/config.toml.backup" ]; then
            mv "$HOME_DIR/config/config.toml.backup" "$HOME_DIR/config/config.toml"
        fi
        return 1
    }
    
    # Step 5: Start node with state sync
    print_status "🚀 Starting node with state sync..."
    start_node
    
    # Step 6: Monitor recovery progress using reusable function
    print_status "📊 Monitoring state sync progress..."
    
    # Use the reusable wait_for_sync_completion function
    if wait_for_sync_completion 600 true; then
        # Sync completed successfully
        print_success "✅ State sync completed successfully!"
        
        # Reset recovery tracking
        recovery_attempts=0
        last_recovery_time=0
        
        # Disable state sync for future restarts
        sed -i.tmp -e '/^\[statesync\]/,/^\[/{s/^enable = .*/enable = false/}' "$HOME_DIR/config/config.toml"
        
        return 0
    else
        # Sync failed or timed out
        print_error "❌ State sync failed or timed out"
        return 1
    fi
}

# Check for sync stall and trigger recovery if needed
check_sync_stall() {
    local current_height="$1"
    local current_time=$(date +%s)
    
    # Check if height has changed
    if [ "$current_height" = "$previous_sync_height" ] && [ "$previous_sync_height" != "0" ]; then
        # Height hasn't changed, check stall duration
        local stall_duration=$((current_time - last_height_change_time))
        
        if [ $stall_duration -gt $SYNC_STALL_THRESHOLD ]; then
            print_warning "⚠️ Sync stalled for $stall_duration seconds (threshold: $SYNC_STALL_THRESHOLD)"
            
            # Check if network is progressing
            local network_height=$(curl -s "$SNAPSHOT_RPC/status" 2>/dev/null | jq -r '.result.sync_info.latest_block_height // "0"')
            
            if [ -n "$network_height" ] && [ "$network_height" != "0" ] && [ "$network_height" != "null" ]; then
                local height_diff=$((network_height - current_height))
                
                if [ $height_diff -gt 100 ]; then
                    print_warning "⚠️ Node is $height_diff blocks behind network"
                    
                    # Trigger automatic recovery
                    print_status "🔄 Triggering automatic snapshot recovery..."
                    recover_from_snapshot "sync stalled for $stall_duration seconds"
                    
                    # Reset tracking after recovery attempt
                    last_height_change_time=$(date +%s)
                    previous_sync_height=0
                    
                    return 0
                fi
            fi
        fi
    else
        # Height changed, update tracking
        last_height_change_time=$current_time
        previous_sync_height=$current_height
    fi
    
    return 1
}

# Enhanced monitor state sync progress with visual progress bars
monitor_state_sync() {
    local sync_start_time=$(date +%s)
    local last_phase=""
    local consecutive_same_phase=0
    local show_detailed_progress="${1:-true}"
    
    # Show initial header
    if [ "$show_detailed_progress" = "true" ]; then
        echo
        print_header "📡 State Sync Progress"
        echo
    fi
    
    while true; do
        # Use our comprehensive status function
        if show_complete_state_sync_status "$sync_start_time" "false"; then
            # State sync completed successfully
            echo
            echo
            print_success "✅ State sync completed successfully!"
            
            # Get final stats
            local elapsed=$(($(date +%s) - sync_start_time))
            local elapsed_min=$((elapsed / 60))
            local elapsed_sec=$((elapsed % 60))
            
            local node_status=$(curl -s localhost:26657/status 2>/dev/null || echo "")
            local final_height="unknown"
            if [ -n "$node_status" ]; then
                final_height=$(echo "$node_status" | jq -r '.result.sync_info.latest_block_height // "unknown"')
            fi
            
            echo "📈 Final height: $final_height"
            echo "⏱️ Total time: ${elapsed_min}m ${elapsed_sec}s"
            echo
            return 0
        fi
        
        local exit_code=$?
        if [ $exit_code -eq 2 ]; then
            # State sync failed
            echo
            echo
            print_error "❌ State sync failed"
            
            # Show some troubleshooting hints
            echo
            print_status "💡 Troubleshooting hints:"
            echo "  • Check logs: push-validator-manager logs"
            echo "  • Try recovery: push-validator-manager recover"
            echo "  • Check network connectivity"
            return 1
        fi
        
        # Check for timeout (15 minutes)
        local elapsed=$(($(date +%s) - sync_start_time))
        if [ $elapsed -gt 900 ]; then
            echo
            echo
            print_error "❌ State sync timeout after 15 minutes"
            
            # Show current phase for debugging
            local current_phase=$(detect_state_sync_phase)
            echo "📊 Last known phase: $current_phase"
            
            # Show troubleshooting hints
            echo
            print_status "💡 Troubleshooting:"
            echo "  • State sync may still be progressing"
            echo "  • Check logs: push-validator-manager logs"
            echo "  • Monitor status: push-validator-manager status"
            return 1
        fi
        
        # Detect if we're stuck in the same phase
        local current_phase=$(detect_state_sync_phase)
        if [ "$current_phase" = "$last_phase" ]; then
            consecutive_same_phase=$((consecutive_same_phase + 1))
        else
            consecutive_same_phase=0
            last_phase="$current_phase"
        fi
        
        # Show warning if stuck in the same phase for too long
        if [ $consecutive_same_phase -gt 20 ] && [ "$current_phase" != "unknown" ]; then
            if [ -t 1 ]; then
                printf "\n${YELLOW}⚠️ Phase '$current_phase' taking longer than expected...${NC}\n"
            fi
            consecutive_same_phase=0  # Reset to avoid spam
        fi
        
        sleep 3
    done
}

# Show logs
show_logs() {
    print_status "📜 Showing Push Chain logs..."
    
    if [ -f "$HOME_DIR/logs/pchaind.log" ]; then
        tail -f "$HOME_DIR/logs/pchaind.log"
    else
        print_warning "⚠️ No log file found"
        if is_node_running; then
            print_status "Node is running but logs not found at expected location"
        else
            print_status "Start the node first: push-validator-manager start"
        fi
    fi
}

# Monitor sync progress
monitor_sync() {
    MONITOR_STOPPED=0
    # Options: default is compact single-line; use -d/--dashboard for full-screen
    local COMPACT_MODE=1
    for arg in "$@"; do
        case "$arg" in
            -d|--dashboard)
                COMPACT_MODE=0
                ;;
            -c|--compact)
                COMPACT_MODE=1
                ;;
        esac
    done

    if ! is_node_running; then
        echo  # Add blank line for spacing
        print_error "❌ Node is not running"
        echo "Start the node first: push-validator-manager start"
        exit 1
    fi
    
    # Check if curl and jq are available
    if ! command -v curl >/dev/null 2>&1 || ! command -v jq >/dev/null 2>&1; then
        echo  # Add blank line for spacing
        print_error "❌ curl or jq not available"
        print_status "Install with: sudo apt-get install curl jq (Linux) or brew install curl jq (macOS)"
        exit 1
    fi
    
    local previous_height=0
    local start_time=$(date +%s)
    local last_time=$start_time

    # Prepare terminal for in-place updates when stdout is a TTY
    local is_tty=0
    if [ -t 1 ]; then
        is_tty=1
        tput civis 2>/dev/null || true
        # On Ctrl+C, restore cursor and exit successfully so callers (like install.sh)
        # don't treat this as a failure. Node continues running.
        trap 'MONITOR_STOPPED=1; tput cnorm 2>/dev/null || true; echo; echo "📊 Sync monitoring stopped. Node continues running in background."; exit 0' INT
        trap 'tput cnorm 2>/dev/null || true' TERM EXIT
        # Don't clear screen to avoid flicker
        # printf '\033[2J\033[H'
    fi
    
    while true; do
        # Move cursor to top-left and clear to end (TTY only)
        [ "${MONITOR_STOPPED:-0}" -eq 1 ] && break
        # Ensure is_synced is defined for this loop iteration (set -u safe)
        local is_synced=0
        if [ "$is_tty" -eq 1 ] && [ "$COMPACT_MODE" -eq 0 ]; then
            tput cup 0 0 2>/dev/null || printf '\033[H'
            tput ed 2>/dev/null || printf '\033[J'
        fi
        
        # Get node status
                NODE_STATUS=$(http_get_quick http://localhost:26657/status 2)
        
        if [ -n "$NODE_STATUS" ]; then
            # Extract sync information
            LOCAL_HEIGHT=$(echo "$NODE_STATUS" | jq -r '.result.sync_info.latest_block_height // "0"' 2>/dev/null || echo "0")
            CATCHING_UP=$(echo "$NODE_STATUS" | jq -r '.result.sync_info.catching_up // "true"' 2>/dev/null || echo "true")
            LATEST_TIME=$(echo "$NODE_STATUS" | jq -r '.result.sync_info.latest_block_time // "unknown"' 2>/dev/null || echo "unknown")
            
            # Fetch remote (network) latest height to compute progress
                    REMOTE_STATUS=$(http_get_quick "$GENESIS_RPC/status" 3)
            REMOTE_HEIGHT=$(echo "$REMOTE_STATUS" | jq -r '.result.sync_info.latest_block_height // "0"' 2>/dev/null || echo "0")
            # Normalize to integers if possible
            [[ "$REMOTE_HEIGHT" =~ ^[0-9]+$ ]] || REMOTE_HEIGHT=0
            
            # Only show progress once we have valid remote height (prevents /0 display)
            # But allow the check to continue for network info and other status

            # Get network information
            MONIKER=$(echo "$NODE_STATUS" | jq -r '.result.node_info.moniker // "unknown"' 2>/dev/null || echo "unknown")
            NETWORK=$(echo "$NODE_STATUS" | jq -r '.result.node_info.network // "unknown"' 2>/dev/null || echo "unknown")
            
            # Calculate sync rate
            local current_time=$(date +%s)
            local elapsed=$((current_time - start_time))
            local interval=$((current_time - last_time))
            [ $interval -le 0 ] && interval=1
            local height_diff=$((LOCAL_HEIGHT - previous_height))
            local blocks_per_sec=$(echo "scale=2; $height_diff / $interval" | bc 2>/dev/null || echo "0")
            
            # Compute progress percentage and render a progress bar
            PROGRESS_PERCENT="0.00"
            if [ "$REMOTE_HEIGHT" -gt 0 ]; then
                if [ "$LOCAL_HEIGHT" -ge "$REMOTE_HEIGHT" ]; then
                    PROGRESS_PERCENT="100.00"
                else
                    PROGRESS_PERCENT=$(echo "scale=2; 100 * $LOCAL_HEIGHT / $REMOTE_HEIGHT" | bc 2>/dev/null || echo "0.00")
                fi
            fi
            BAR_WIDTH=$(compute_bar_width)
            FILLED=$(echo "$PROGRESS_PERCENT * $BAR_WIDTH / 100" | bc 2>/dev/null | cut -d'.' -f1)
            [ -z "$FILLED" ] && FILLED=0
            # Ensure at least 1 cell shows when progress > 0
            if [ "$FILLED" -eq 0 ] && [ "$PROGRESS_PERCENT" != "0.00" ]; then
                FILLED=1
            fi
            [ "$FILLED" -gt "$BAR_WIDTH" ] && FILLED=$BAR_WIDTH
            EMPTY=$((BAR_WIDTH - FILLED))
            BAR_FILLED=$(printf "%0.s█" $(seq 1 ${FILLED}))
            BAR_EMPTY=$(printf "%0.s░" $(seq 1 ${EMPTY}))
            PROGRESS_BAR="${GREEN}${BAR_FILLED}${NC}${DIM}${BAR_EMPTY}${NC}"
            
            if [ "$COMPACT_MODE" -eq 1 ]; then
                # Single-line compact output with colors
                local status_text="${YELLOW}⏳ SYNCING${NC}"
                # Determine actual sync status based on height comparison
                if [ "$REMOTE_HEIGHT" -gt 0 ]; then
                    HEIGHT_DIFF=$((REMOTE_HEIGHT - LOCAL_HEIGHT))
                    if [ "$HEIGHT_DIFF" -le 5 ]; then
                        status_text="${GREEN}✅ SYNCED${NC}"
                        is_synced=1
                    elif [ "$HEIGHT_DIFF" -gt 5 ] && [ "$HEIGHT_DIFF" -le 100 ]; then
                        status_text="${YELLOW}🔄 CATCHING UP${NC}"
                    else
                        status_text="${YELLOW}⏳ SYNCING${NC}"
                    fi
                elif [ "$CATCHING_UP" = "false" ]; then
                    status_text="${GREEN}✅ SYNCED${NC}"
                    is_synced=1
                fi
                local eta_text=""
                HEIGHT_DIFF=$((REMOTE_HEIGHT - LOCAL_HEIGHT))
                if [ "$HEIGHT_DIFF" -gt 5 ] && [ "$REMOTE_HEIGHT" -gt "$LOCAL_HEIGHT" ]; then
                    REMAINING_BLOCKS=$((REMOTE_HEIGHT - LOCAL_HEIGHT))
                    RATE_POS=$(echo "$blocks_per_sec > 0" | bc 2>/dev/null || echo 0)
                    if [ "$RATE_POS" -eq 1 ]; then
                        ETA_SECONDS=$(echo "$REMAINING_BLOCKS / $blocks_per_sec" | bc 2>/dev/null || echo 0)
                        if [ "$ETA_SECONDS" -gt 0 ] 2>/dev/null; then
                            ETA_H=$((ETA_SECONDS / 3600))
                            ETA_M=$(((ETA_SECONDS % 3600) / 60))
                            ETA_S=$((ETA_SECONDS % 60))
                            if [ "$ETA_H" -gt 0 ]; then
                                eta_text=" ${WHITE}~${NC}${GREEN}${ETA_H}h ${ETA_M}m${NC}"
                            elif [ "$ETA_M" -gt 0 ]; then
                                eta_text=" ${WHITE}~${NC}${GREEN}${ETA_M}m ${ETA_S}s${NC}"
                            else
                                eta_text=" ${WHITE}~${NC}${GREEN}${ETA_S}s${NC}"
                            fi
                        fi
                    fi
                fi
                # Build colored single-line summary with progress bar and print in place
                # Only show when we have valid remote height (prevents /0 display)
                if [ "$REMOTE_HEIGHT" -gt 0 ]; then
                    local line="${status_text} [${PROGRESS_BAR}] ${GREEN}${PROGRESS_PERCENT}%${NC} | ${BOLD}${WHITE}Height${NC} ${MAGENTA}${LOCAL_HEIGHT}${NC}/${MAGENTA}${REMOTE_HEIGHT}${NC} | ${BOLD}${WHITE}Rate${NC} ${CYAN}${blocks_per_sec}${NC} blk/s${eta_text}"
                    [ "${MONITOR_STOPPED:-0}" -eq 1 ] && break
                    printf "\r%b\033[K" "$line"
                fi
            else
                # Full-screen rich output
                echo -e "${BOLD}${GREEN}Push Chain Sync Monitor${NC}"
                echo -e "${GREEN}═══════════════════════════════════════════${NC}"
                echo
                print_header "Node Information:"
                echo -e "  ${BOLD}Moniker:${NC} ${WHITE}$MONIKER${NC}"
                echo -e "  ${BOLD}Network:${NC} ${GREEN}$NETWORK${NC}"
                echo
                
                print_header "Sync Status:"
                echo -e "  ${BOLD}Block Height:${NC} ${MAGENTA}$LOCAL_HEIGHT${NC}"
                echo -e "  ${BOLD}Last Block:${NC} $LATEST_TIME"
                
                # Determine actual sync status based on height comparison
                if [ "$REMOTE_HEIGHT" -gt 0 ]; then
                    HEIGHT_DIFF=$((REMOTE_HEIGHT - LOCAL_HEIGHT))
                    if [ "$HEIGHT_DIFF" -le 5 ]; then
                        is_synced=1
                        echo -e "  ${BOLD}Status:${NC} ${GREEN}✅ FULLY SYNCED${NC}"
                        echo -e "  ${BOLD}Sync Rate:${NC} ${GREEN}Maintaining sync${NC}"
                    elif [ "$HEIGHT_DIFF" -gt 5 ] && [ "$HEIGHT_DIFF" -le 100 ]; then
                        echo -e "  ${BOLD}Status:${NC} ${YELLOW}🔄 CATCHING UP${NC} (${HEIGHT_DIFF} blocks behind)"
                    else
                        echo -e "  ${BOLD}Status:${NC} ${YELLOW}⏳ SYNCING...${NC}"
                    fi
                elif [ "$CATCHING_UP" = "false" ]; then
                    is_synced=1
                    echo -e "  ${BOLD}Status:${NC} ${GREEN}✅ FULLY SYNCED${NC}"
                    echo -e "  ${BOLD}Sync Rate:${NC} ${GREEN}Maintaining sync${NC}"
                else
                    echo -e "  ${BOLD}Status:${NC} ${YELLOW}⏳ SYNCING...${NC}"
                fi
                
                if [ "$is_synced" -eq 0 ]; then
                    if [ "$blocks_per_sec" != "0" ]; then
                        echo -e "  ${BOLD}Sync Rate:${NC} ${CYAN}${blocks_per_sec} blocks/sec${NC}"
                        # Estimate ETA based on remaining blocks and current rate
                        if [ "$REMOTE_HEIGHT" -gt "$LOCAL_HEIGHT" ]; then
                            REMAINING_BLOCKS=$((REMOTE_HEIGHT - LOCAL_HEIGHT))
                            RATE_POS=$(echo "$blocks_per_sec > 0" | bc 2>/dev/null || echo 0)
                            if [ "$RATE_POS" -eq 1 ]; then
                                ETA_SECONDS=$(echo "$REMAINING_BLOCKS / $blocks_per_sec" | bc 2>/dev/null || echo 0)
                                if [ "$ETA_SECONDS" -gt 0 ] 2>/dev/null; then
                                    ETA_H=$((ETA_SECONDS / 3600))
                                    ETA_M=$(((ETA_SECONDS % 3600) / 60))
                                    ETA_S=$((ETA_SECONDS % 60))
                                    if [ "$ETA_H" -gt 0 ]; then
                                        echo -e "  ${BOLD}ETA:${NC} ~${GREEN}${ETA_H}h ${ETA_M}m${NC}"
                                    elif [ "$ETA_M" -gt 0 ]; then
                                        echo -e "  ${BOLD}ETA:${NC} ~${GREEN}${ETA_M}m ${ETA_S}s${NC}"
                                    else
                                        echo -e "  ${BOLD}ETA:${NC} ~${GREEN}${ETA_S}s${NC}"
                                    fi
                                fi
                            fi
                        fi
                    fi
                fi
                
                echo
                print_header "Runtime Stats:"
                echo -e "  ${BOLD}Monitoring Time:${NC} ${elapsed}s"
                if [ "$REMOTE_HEIGHT" -gt 0 ]; then
                    echo -e "  ${BOLD}Progress:${NC} [${PROGRESS_BAR}] ${GREEN}${PROGRESS_PERCENT}%${NC} (${MAGENTA}${LOCAL_HEIGHT}${NC}/${MAGENTA}${REMOTE_HEIGHT}${NC})"
                else
                    echo -e "  ${BOLD}Progress:${NC} [${PROGRESS_BAR}] ${YELLOW}unknown target height${NC} (${MAGENTA}${LOCAL_HEIGHT}${NC}/?)"
                fi
                
                if [ "$is_synced" -eq 1 ]; then
                    echo
                    echo -e "${BOLD}${GREEN}🎉 Node is fully synced and ready!${NC}"
                    echo -e "You can now register as validator: ${BOLD}push-validator-manager register-validator${NC}"
                fi
                
                echo
                print_status "Press Ctrl+C to exit monitor"
            fi

            # Check for sync stall and trigger recovery if needed
            if [ "$is_synced" -eq 0 ] && [ "$AUTO_RECOVERY_ENABLED" = "true" ]; then
                if check_sync_stall "$LOCAL_HEIGHT"; then
                    # Recovery was triggered, restart monitoring
                    print_status "🔄 Restarting sync monitoring after recovery..."
                    sleep 5
                    continue
                fi
            fi
            
            previous_height=$LOCAL_HEIGHT
            last_time=$current_time
            
        else
            # Silently wait for node to respond
            :
        fi
        
        if [ "$COMPACT_MODE" -eq 1 ]; then
            sleep 1
        else
            sleep 3
        fi
    done
}

# Register validator
register_validator() {
    echo  # Add blank line for spacing
    print_status "🚀 Starting validator registration..."
    
    if [ -f "$SCRIPT_DIR/scripts/register-validator.sh" ]; then
        bash "$SCRIPT_DIR/scripts/register-validator.sh"
    else
        print_error "❌ Validator registration script not found!"
        exit 1
    fi
}

# Configure genesis RPC endpoint
configure_genesis() {
    if [ -n "${2-}" ]; then
        NEW_GENESIS_DOMAIN="$2"
        print_status "🔧 Setting genesis RPC domain to: $NEW_GENESIS_DOMAIN"
        
        # Create/update .env file for persistence
        ENV_FILE="$SCRIPT_DIR/.env"
        if [ -f "$ENV_FILE" ]; then
            # Remove existing GENESIS_DOMAIN line
            grep -v "^GENESIS_DOMAIN=" "$ENV_FILE" > "$ENV_FILE.tmp" && mv "$ENV_FILE.tmp" "$ENV_FILE" || touch "$ENV_FILE"
        fi
        echo "GENESIS_DOMAIN=$NEW_GENESIS_DOMAIN" >> "$ENV_FILE"
        
        print_success "✅ Genesis RPC configured: https://$NEW_GENESIS_DOMAIN"
        print_status "💡 This setting will persist across restarts"

        # If node already initialized, update persistent_peers accordingly
        if [ -f "$HOME_DIR/config/config.toml" ]; then
            # Try to get multiple peers from the new genesis domain
            NEW_PEERS=""
            PEERS_JSON=$(http_get_quick "https://$NEW_GENESIS_DOMAIN/net_info" 3)
            [ -n "$PEERS_JSON" ] || PEERS_JSON='{}'
            
            if [ -n "$PEERS_JSON" ] && [ "$PEERS_JSON" != '{}' ]; then
                # Filter out peers with misconfigured listen_addr (0.0.0.0) and get only properly configured peers
                PEER_LIST=$(echo "$PEERS_JSON" | jq -r '.result.peers[]? | select(.node_info.listen_addr | contains("0.0.0.0") | not) | "\(.node_info.id)@\(.remote_ip):26656"' 2>/dev/null | head -3 || true)
                if [ -n "$PEER_LIST" ]; then
                    NEW_PEERS=$(echo "$PEER_LIST" | tr '\n' ',' | sed 's/,$//')
                    print_status "✅ Found $(echo "$PEER_LIST" | wc -l | tr -d ' ') properly configured peers for new domain"
                else
                    print_status "⚠️ No properly configured peers found for new domain, using fallback"
                fi
            fi
            
            # Fallback to single peer
            if [ -z "$NEW_PEERS" ]; then
                NEW_NODE_ID=$(http_get_quick "https://$NEW_GENESIS_DOMAIN/status" 3 | jq -r '.result.node_info.id // empty' || true)
                NEW_IP=$(resolve_host_ip "$NEW_GENESIS_DOMAIN")
                if [ -n "$NEW_NODE_ID" ] && [ -n "$NEW_IP" ]; then
                    NEW_PEERS="$NEW_NODE_ID@$NEW_IP:26656"
                fi
            fi
            
            if [ -n "$NEW_PEERS" ]; then
                sed -i.bak -e "s/^persistent_peers = .*/persistent_peers = \"$NEW_PEERS\"/" -e "s/^addr_book_strict = .*/addr_book_strict = false/" "$HOME_DIR/config/config.toml"
                print_success "🔗 Updated persistent_peers to $NEW_PEERS"
                print_status "🔄 Restart the node to apply the new peers: push-validator-manager restart"
            else
                print_warning "⚠️ Could not resolve new peer info; leaving config unchanged."
            fi
        else
            print_status "🔄 Start will use the new endpoint on first initialization"
        fi
    else
        print_header "📡 Current Genesis RPC Configuration"
        echo -e "${GREEN}══════════════════════════════════════${NC}"
        echo -e "  ${BOLD}Domain:${NC} ${MAGENTA}$GENESIS_DOMAIN${NC}"
        echo -e "  ${BOLD}Full URL:${NC} ${MAGENTA}$GENESIS_RPC${NC}"
        echo
        print_status "💡 To change: push-validator-manager set-genesis <domain>"
        print_status "   Example: push-validator-manager set-genesis rpc.custom-node.org"
        echo
        print_status "🔧 Default: rpc-testnet-donut-node1.push.org"
    fi
}

# Check wallet balance
check_balance() {
    WALLET_NAME="${2:-validator-key}"
    print_status "💰 Checking wallet balance..."
    
    # Check if wallet exists
    if ! "$PCHAIND" keys show "$WALLET_NAME" --keyring-backend "$KEYRING_BACKEND" --home "$HOME_DIR" >/dev/null 2>&1; then
        print_error "❌ Wallet '$WALLET_NAME' not found!"
        echo "Create a wallet first using: push-validator-manager register-validator"
        exit 1
    fi
    
    # Get address
    ADDRESS=$("$PCHAIND" keys show "$WALLET_NAME" -a --keyring-backend "$KEYRING_BACKEND" --home "$HOME_DIR" 2>/dev/null)
    
    echo "Wallet: $WALLET_NAME"
    echo "Address: $ADDRESS"
    
    # Get balance from remote RPC for accuracy
    BALANCE=$("$PCHAIND" query bank balances "$ADDRESS" --node "tcp://$GENESIS_DOMAIN:26657" -o json 2>/dev/null | \
        jq -r '.balances[] | select(.denom=="upc") | .amount // "0"' || echo "0")
    
    if [ "$BALANCE" != "0" ] && [ -n "$BALANCE" ]; then
        # Convert to PUSH (divide by 10^18) using awk
        PUSH_AMOUNT=$(awk -v bal="$BALANCE" 'BEGIN {printf "%.6f", bal/1000000000000000000}')
        print_success "Balance: $PUSH_AMOUNT PUSH"
    else
        print_warning "Balance: 0 PUSH"
        
        # Convert to EVM address for faucet
        EVM_ADDRESS=$("$PCHAIND" debug addr "$ADDRESS" --home "$HOME_DIR" 2>/dev/null | grep "hex" | awk '{print "0x"$3}')
        
        if [ -n "$EVM_ADDRESS" ]; then
            echo
            echo "To get test tokens:"
            echo -e "${GREEN}1. Visit: https://faucet.push.org${NC}"
            echo -e "${GREEN}2. Use this address: ${BOLD}$EVM_ADDRESS${NC}"
        else
            echo "Get test tokens at: https://faucet.push.org"
        fi
    fi
}

# List validators
list_validators() {
    print_header "👥 Active Push Chain Validators"
    echo -e "${GREEN}═══════════════════════════════════════════════════════════════${NC}"
    
    if is_node_running; then
        # Always use remote RPC for validator queries since we need network-wide data
        NODE_ENDPOINT="tcp://$GENESIS_DOMAIN:26657"
        
        VALIDATORS=$("$PCHAIND" query staking validators --output json --node "$NODE_ENDPOINT" 2>/dev/null | jq -r '.validators[]' 2>/dev/null || echo "")
        
        if [ -n "$VALIDATORS" ]; then
            echo
            printf "${BOLD}${YELLOW}%-26s %-12s %12s %11s${NC}\n" "VALIDATOR" "STATUS" "STAKE (PC)" "COMMISSION"
            echo -e "${BLUE}─────────────────────────────────────────────────────────────────${NC}"
            
            echo "$VALIDATORS" | jq -r '
                (.description.moniker // "unknown") + "|" + 
                (if .status == "BOND_STATUS_BONDED" then "BONDED" 
                 elif .status == "BOND_STATUS_UNBONDING" then "UNBONDING"
                 elif .status == "BOND_STATUS_UNBONDED" then "UNBONDED"
                 else .status end) + "|" +
                ((.tokens | tonumber / 1000000000000000000) | tostring | split(".")[0]) + "|" +
                ((.commission.commission_rates.rate | tonumber * 100) | tostring | split(".")[0]) + "%"
            ' 2>/dev/null | while IFS='|' read -r moniker status tokens commission; do
                # Pre-pad fields WITHOUT color so width counts are correct
                moniker_padded=$(printf "%-26s" "$moniker")
                status_padded=$(printf "%-12s" "$status")
                tokens_padded=$(printf "%12s" "$tokens")
                commission_padded=$(printf "%11s" "$commission")

                # Apply colors after padding
                case "$status" in
                    "BONDED")     status_colored="${GREEN}${status_padded}${NC}" ;;
                    "UNBONDING")  status_colored="${YELLOW}${status_padded}${NC}" ;;
                    "UNBONDED")   status_colored="${RED}${status_padded}${NC}" ;;
                    *)             status_colored="${CYAN}${status_padded}${NC}" ;;
                esac

                echo -e "${BOLD}${moniker_padded}${NC} ${status_colored} ${MAGENTA}${tokens_padded}${NC} ${MAGENTA}${commission_padded}${NC}"
            done
            
            echo
            print_status "Total Validators: $(echo "$VALIDATORS" | jq -s length)"
        else
            print_warning "No validators found or node not synced"
        fi
    else
        print_error "❌ Node must be running to query validators"
        echo "Start the node first: push-validator-manager start"
    fi
}

# Show help
show_help() {
    echo
    echo -e "${BOLD}${GREEN}Push Validator Manager${NC}"
    echo -e "${CYAN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo
    echo -e "${BOLD}Usage:${NC} push-validator-manager [command] [options]"
    echo
    echo -e "${BOLD}${CYAN}CORE COMMANDS${NC}"
    printf "  ${BOLD}%-18s${NC}%s\n" "start" "Start the Push node"
    printf "  ${BOLD}%-18s${NC}%s\n" "stop" "Stop the Push node"
    printf "  ${BOLD}%-18s${NC}%s\n" "status" "Check node status"
    printf "  ${BOLD}%-18s${NC}%s\n" "sync [-d]" "Monitor sync. Use -d for dashboard"
    printf "  ${BOLD}%-18s${NC}%s\n" "monitor-state-sync" "Enhanced state sync monitoring"
    printf "  ${BOLD}%-18s${NC}%s\n" "logs" "View node logs"
    echo
    echo -e "${BOLD}${CYAN}VALIDATOR${NC}"
    echo -e "  ${BOLD}register-validator${NC}  Register as validator"
    echo -e "  ${BOLD}validators${NC}          List all validators"
    echo -e "  ${BOLD}balance${NC} [wallet]    Check wallet balance"
    echo
    echo -e "${BOLD}${CYAN}CONFIGURATION${NC}"
    echo -e "  ${BOLD}set-genesis${NC} <url>   Set genesis RPC endpoint"
    echo -e "  ${BOLD}reset${NC}               Reset blockchain data"
    echo -e "  ${BOLD}setup-deps${NC}          Install dependencies"
    echo
    echo -e "${BOLD}${CYAN}RECOVERY${NC}"
    echo -e "  ${BOLD}recover${NC}             Manual snapshot recovery"
    echo -e "  ${BOLD}recovery-status${NC}     Show recovery configuration"
    echo
    echo -e "${CYAN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo -e "${BOLD}${YELLOW}QUICK START${NC}"
    echo -e "  1. push-validator-manager ${BOLD}start${NC}"
    echo -e "  2. push-validator-manager ${BOLD}status${NC}"
    echo -e "  3. push-validator-manager ${BOLD}register-validator${NC}"
    echo
    echo -e "${CYAN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo -e "${BOLD}NETWORK${NC}"
    echo -e "  Chain ID:    ${YELLOW}push_42101-1${NC}"
    echo -e "  Network:     ${YELLOW}Testnet${NC}"
    echo -e "  RPC:         ${YELLOW}http://localhost:26657${NC}"
    echo -e "  Genesis RPC: ${YELLOW}https://$GENESIS_DOMAIN${NC}"
    echo -e "  Faucet:      ${YELLOW}https://faucet.push.org${NC}"
    echo
    echo -e "${BOLD}DATA LOCATIONS${NC}"
    echo -e "  Node data:   ${YELLOW}~/.pchain${NC}"
    echo -e "  Logs:        ${YELLOW}~/.pchain/logs/pchaind.log${NC}"
    echo
    echo -e "${CYAN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo -e "${BOLD}AUTOMATIC RECOVERY SETTINGS${NC}"
    echo -e "  ${YELLOW}AUTO_RECOVERY_ENABLED${NC}=true     Enable auto recovery"
    echo -e "  ${YELLOW}SYNC_STALL_THRESHOLD${NC}=120       Seconds before recovery"
    echo -e "  ${YELLOW}MAX_RECOVERY_ATTEMPTS${NC}=3        Max recovery attempts"
    echo -e "  ${YELLOW}SNAPSHOT_RPC${NC}=<url>             RPC for snapshots"
    echo
}

# Command handling
###############################################################################
# WebSocket-driven sync monitoring (with graceful fallback)
###############################################################################

# Optional user hook: override this function in the environment to run custom
# actions once the node is fully synced. Default prints helpful guidance.
on_fully_synced() {
    print_success "🎉 Node is fully synced and ready!"
    echo -e "You can now register as validator: ${BOLD}push-validator-manager register-validator${NC}"
    # If a user-provided hook script exists, run it
    if [ -x "$SCRIPT_DIR/scripts/on-synced.sh" ]; then
        "$SCRIPT_DIR/scripts/on-synced.sh" || true
    fi
}

# Try WebSocket monitor first; if unavailable, fall back to the existing polling
monitor_sync_auto() {
    # Run monitors in subshells to isolate traps and avoid double-handling Ctrl+C
    ( monitor_sync_ws "$@" ) && return 0
    ( monitor_sync "$@" )
}

# WebSocket monitor using websocat or wscat
monitor_sync_ws() {
    MONITOR_STOPPED=0
    
    # Options: default is compact single-line; use -d/--dashboard for full-screen
    local COMPACT_MODE=1
    for arg in "$@"; do
        case "$arg" in
            -d|--dashboard) COMPACT_MODE=0 ;;
            -c|--compact) COMPACT_MODE=1 ;;
        esac
    done

    # Require running node
    if ! is_node_running; then
        echo
        print_error "❌ Node is not running"
        echo "Start the node first: push-validator-manager start"
        return 1
    fi

    # Detect WebSocket client
    local WS_CLIENT=""
    if command -v websocat >/dev/null 2>&1; then
        WS_CLIENT="websocat"
    elif command -v wscat >/dev/null 2>&1; then
        WS_CLIENT="wscat"
    else
        print_warning "⚠️ No WebSocket client (websocat/wscat) found; falling back to polling."
        return 1
    fi

    local start_time=$(date +%s)
    local last_time=$start_time
    local previous_height=0
    local last_event_time=$start_time
    local avg_interval_sum=0
    local avg_interval_count=0
    local REMOTE_HEIGHT=0
    local last_remote_poll=$start_time
    local FULLY_SYNCED_ONCE=0
    local reconnects=0
    local LOCAL_HEIGHT=0

    # Prepare terminal when TTY
    local is_tty=0
    if [ -t 1 ]; then
        is_tty=1
        tput civis 2>/dev/null || true
        trap 'MONITOR_STOPPED=1; tput cnorm 2>/dev/null || true; echo; echo "📊 Sync monitoring stopped. Node continues running in background."; exit 0' INT
    fi

    # Helper: render current status in compact or dashboard mode
    render_ws_view() {
        [ "${MONITOR_STOPPED:-0}" -eq 1 ] && return 0
        local current_time=$(date +%s)
        local elapsed=$((current_time - start_time))

        # Refresh remote height every 5 seconds for accurate percentage/ETA
        if [ $((current_time - last_remote_poll)) -ge 5 ]; then
            local REMOTE_STATUS=$(http_get_quick "$GENESIS_RPC/status" 3)
            local RH=$(echo "$REMOTE_STATUS" | jq -r '.result.sync_info.latest_block_height // "0"' 2>/dev/null || echo "0")
            [[ "$RH" =~ ^[0-9]+$ ]] || RH=0
            REMOTE_HEIGHT=$RH
            last_remote_poll=$current_time
        fi

        # Compute blocks/sec using previous_height/last_time deltas
        local interval=$((current_time - last_time)); [ $interval -le 0 ] && interval=1
        local height_diff=$((LOCAL_HEIGHT - previous_height))
        local blocks_per_sec=$(echo "scale=2; $height_diff / $interval" | bc 2>/dev/null || echo "0")

        # Progress bar
        local PROGRESS_PERCENT="0.00"
        if [ "$REMOTE_HEIGHT" -gt 0 ]; then
            if [ "$LOCAL_HEIGHT" -ge "$REMOTE_HEIGHT" ]; then
                PROGRESS_PERCENT="100.00"
            else
                PROGRESS_PERCENT=$(echo "scale=2; 100 * $LOCAL_HEIGHT / $REMOTE_HEIGHT" | bc 2>/dev/null || echo "0.00")
            fi
        fi
        local BAR_WIDTH=$(compute_bar_width)
        local FILLED=$(echo "$PROGRESS_PERCENT * $BAR_WIDTH / 100" | bc 2>/dev/null | cut -d'.' -f1)
        [ -z "$FILLED" ] && FILLED=0
        if [ "$FILLED" -eq 0 ] && [ "$PROGRESS_PERCENT" != "0.00" ]; then
            FILLED=1
        fi
        [ "$FILLED" -gt "$BAR_WIDTH" ] && FILLED=$BAR_WIDTH
        local EMPTY=$((BAR_WIDTH - FILLED))
        local BAR_FILLED=$(printf "%0.s█" $(seq 1 ${FILLED}))
        local BAR_EMPTY=$(printf "%0.s░" $(seq 1 ${EMPTY}))
        local PROGRESS_BAR="${GREEN}${BAR_FILLED}${NC}${DIM}${BAR_EMPTY}${NC}"

        # Connection quality: degrade with reconnects and long gaps
        local gap=$((current_time - last_event_time))
        local quality=$((100 - reconnects*15))
        [ $quality -lt 10 ] && quality=10
        if [ $gap -gt 10 ]; then quality=$((quality - 20)); [ $quality -lt 5 ] && quality=5; fi
        local quality_text="Good"; [ $quality -lt 70 ] && quality_text="OK"; [ $quality -lt 40 ] && quality_text="Poor"

        # Average block interval (seconds)
        local avg_block_time=""
        if [ $avg_interval_count -gt 0 ]; then
            avg_block_time=$(echo "scale=2; $avg_interval_sum / $avg_interval_count" | bc 2>/dev/null || echo "0")
        else
            avg_block_time="0"
        fi

        # Status text based on proximity to head
        local status_text="${YELLOW}⏳ SYNCING${NC}"
        if [ "$REMOTE_HEIGHT" -gt 0 ]; then
            local HEIGHT_DIFF=$((REMOTE_HEIGHT - LOCAL_HEIGHT))
            if [ "$HEIGHT_DIFF" -le 5 ]; then
                status_text="${GREEN}✅ SYNCED${NC}"
            elif [ "$HEIGHT_DIFF" -le 100 ]; then
                status_text="${YELLOW}🔄 CATCHING UP${NC}"
            fi
        fi

        if [ "${MONITOR_STOPPED:-0}" -eq 1 ]; then return 0; fi
        if [ "$COMPACT_MODE" -eq 1 ]; then
            # Compose single-line summary with bar and ETA
            local eta_text=""
            local HEIGHT_DIFF=$((REMOTE_HEIGHT - LOCAL_HEIGHT))
            if [ "$HEIGHT_DIFF" -gt 5 ] && [ "$REMOTE_HEIGHT" -gt "$LOCAL_HEIGHT" ]; then
                local REMAINING_BLOCKS=$HEIGHT_DIFF
                local RATE_POS=$(echo "$blocks_per_sec > 0" | bc 2>/dev/null || echo 0)
                if [ "$RATE_POS" -eq 1 ]; then
                    local ETA_SECONDS=$(echo "$REMAINING_BLOCKS / $blocks_per_sec" | bc 2>/dev/null || echo 0)
                    if [ "$ETA_SECONDS" -gt 0 ] 2>/dev/null; then
                        local ETA_H=$((ETA_SECONDS / 3600))
                        local ETA_M=$(((ETA_SECONDS % 3600) / 60))
                        local ETA_S=$((ETA_SECONDS % 60))
                        if [ "$ETA_H" -gt 0 ]; then
                            eta_text=" ${WHITE}~${NC}${GREEN}${ETA_H}h ${ETA_M}m${NC}"
                        elif [ "$ETA_M" -gt 0 ]; then
                            eta_text=" ${WHITE}~${NC}${GREEN}${ETA_M}m ${ETA_S}s${NC}"
                        else
                            eta_text=" ${WHITE}~${NC}${GREEN}${ETA_S}s${NC}"
                        fi
                    fi
                fi
            fi
            local line="${status_text} [${PROGRESS_BAR}] ${GREEN}${PROGRESS_PERCENT}%${NC} | ${BOLD}${WHITE}Height${NC} ${MAGENTA}${LOCAL_HEIGHT}${NC}/${MAGENTA}${REMOTE_HEIGHT}${NC} | ${BOLD}${WHITE}Rate${NC} ${CYAN}${blocks_per_sec}${NC} blk/s${eta_text}"
            [ "${MONITOR_STOPPED:-0}" -eq 1 ] && return 0
            printf "\r%b\033[K" "$line"
        else
            if [ "$is_tty" -eq 1 ]; then
                tput cup 0 0 2>/dev/null || printf '\033[H'
                tput ed 2>/dev/null || printf '\033[J'
            fi
            [ "${MONITOR_STOPPED:-0}" -eq 1 ] && return 0
            echo -e "${BLUE}📊 Push Chain Sync (WebSocket)${NC}"
            echo -e "${GREEN}══════════════════════════════════════════${NC}"
            echo -e "  ${BOLD}Block Height:${NC} ${MAGENTA}${LOCAL_HEIGHT:-0}${NC}/${MAGENTA}${REMOTE_HEIGHT:-0}${NC}"
            echo -e "  ${BOLD}Status:${NC} $status_text"
            echo -e "  ${BOLD}Rate:${NC} ${CYAN}${blocks_per_sec} blocks/sec${NC}"
            echo -e "  ${BOLD}Avg Block Time:${NC} ${CYAN}${avg_block_time}s${NC}"
            echo -e "  ${BOLD}Connection:${NC} ${CYAN}${quality_text}${NC} (${quality}%)"
            echo -e "  ${BOLD}Progress:${NC} [${PROGRESS_BAR}] ${GREEN}${PROGRESS_PERCENT}%${NC}"
            echo -e "  ${BOLD}Monitoring Time:${NC} $((elapsed))s"
            echo
            print_status "Press Ctrl+C to exit monitor"
        fi

            [ "${MONITOR_STOPPED:-0}" -eq 1 ] && return 0
            previous_height=$LOCAL_HEIGHT
            last_time=$current_time
    }

    # Perform an immediate initial fetch to avoid blank screen while connecting
    local INIT_STATUS=$(http_get_quick http://localhost:26657/status 2)
    if [ -n "$INIT_STATUS" ]; then
        LOCAL_HEIGHT=$(echo "$INIT_STATUS" | jq -r '.result.sync_info.latest_block_height // "0"' 2>/dev/null || echo "0")
        [[ "$LOCAL_HEIGHT" =~ ^[0-9]+$ ]] || LOCAL_HEIGHT=0
        previous_height=$LOCAL_HEIGHT
    fi
    # Render once immediately so users see progress without waiting for first event
    render_ws_view || true

    # Subscribe helper: run client and stream events; returns on disconnect
    _run_subscription() {
        local query="$1"
        local payload='{\"jsonrpc\":\"2.0\",\"method\":\"subscribe\",\"params\":{\"query\":'"\"$query\""'},\"id\":1}'
        if [ "$WS_CLIENT" = "websocat" ]; then
            # Send subscribe JSON and stream messages
            # shellcheck disable=SC2005
            ( echo "$payload"; ) | websocat -t ws://localhost:26657/websocket 2>/dev/null
        else
            # wscat can send once with -x and print responses
            wscat -c ws://localhost:26657/websocket -x "$payload" 2>/dev/null
        fi
    }

    # Attempt multiple query forms; keep reconnecting. If we fail repeatedly
    # without receiving any events, let caller fallback to polling.
    local queries=("cometbft.event='NewBlockHeader'" "tm.event='NewBlockHeader'" "tm.event='NewBlock'")
    local noevent_streak=0
    local TMP_RECEIVED="/tmp/pnm_ws_${$}_received"
    # Use a function to clean up to avoid variable evaluation issues
    cleanup_tmp_received() { rm -f "/tmp/pnm_ws_${$}_received" 2>/dev/null || true; }
    trap cleanup_tmp_received EXIT
    : > "$TMP_RECEIVED" 2>/dev/null || true

    while true; do
        local got_event=0
        for q in "${queries[@]}"; do
            : > "$TMP_RECEIVED" 2>/dev/null || true
            # Use process substitution with read timeout so we don't block forever
            exec 3< <(_run_subscription "$q")
            while IFS= read -r -t 2 line <&3; do
            [ "${MONITOR_STOPPED:-0}" -eq 1 ] && break
            # Extract height from either NewBlock or NewBlockHeader shapes
            local h
                h=$(echo "$line" | jq -r '(.result.data.value.block.header.height // .result.data.value.header.height // empty)') || h=""
                if [ -z "$h" ] || [ "$h" = "null" ]; then
                    continue
                fi

                # Normalize height
                if [[ "$h" =~ ^[0-9]+$ ]]; then
                    LOCAL_HEIGHT=$h
                else
                    continue
                fi

                # Mark that we received at least one event in this attempt
                echo 1 > "$TMP_RECEIVED" 2>/dev/null || true

                # Update average block interval from event arrival spacing (wall clock)
                local now=$(date +%s)
                local delta=$((now - last_event_time))
                if [ $delta -gt 0 ]; then
                    avg_interval_sum=$((avg_interval_sum + delta))
                    avg_interval_count=$((avg_interval_count + 1))
                fi
                last_event_time=$now

                # Render UI and possibly invoke hook when considered synced
                render_ws_view

                # Trigger on_fully_synced once when near head
                if [ "${MONITOR_STOPPED:-0}" -eq 0 ] && [ "$FULLY_SYNCED_ONCE" -eq 0 ] && [ "$REMOTE_HEIGHT" -gt 0 ] && [ $((REMOTE_HEIGHT - LOCAL_HEIGHT)) -le 5 ]; then
                    echo
                    on_fully_synced || true
                    FULLY_SYNCED_ONCE=1
                fi
            done
            exec 3<&-

            if [ -s "$TMP_RECEIVED" ]; then
                got_event=1
                break
            fi
            # No events in this attempt; render to keep UI fresh
            render_ws_view || true
        done

        if [ "$got_event" -eq 1 ]; then
            noevent_streak=0
        else
            noevent_streak=$((noevent_streak + 1))
        fi

        reconnects=$((reconnects + 1))

        # If we failed to get events several times in a row, fallback
        if [ "$noevent_streak" -ge 3 ]; then
            # Do not print a newline; let the fallback monitor redraw on the same line
            return 1
        fi

        # Small backoff before trying again
        sleep 2
    done
}

###############################################################################
# Command handling
###############################################################################

case "${1:-help}" in
    start|run)
        show_banner
        start_node
        ;;
        
    stop)
        stop_node
        ;;
        
    restart)
        stop_node
        sleep 2
        start_node
        ;;
        
    status)
        show_status
        ;;
        
    sync)
        monitor_sync_auto ${@:2}
        ;;
        
    logs)
        show_logs
        ;;
        
    register-validator|setup)
        show_banner
        register_validator
        ;;
        
    balance|wallet)
        check_balance "$@"
        ;;
        
    validators)
        list_validators
        ;;
        
    set-genesis)
        configure_genesis "$@"
        ;;
        
    genesis)
        configure_genesis "$@"
        ;;
        
    setup-deps)
        print_status "🔧 Running dependency setup..."
        bash "$SCRIPT_DIR/scripts/setup-dependencies.sh"
        ;;
        
    reset)
        print_warning "⚠️ This will reset all blockchain data (wallets will be preserved)"
        read -p "Continue? (yes/no): " confirm
        if [[ "$confirm" =~ ^[Yy][Ee][Ss]$ ]]; then
            stop_node
            print_status "🧹 Removing blockchain data..."
            rm -rf "$HOME_DIR/data"
            rm -f "$HOME_DIR/config/addrbook.json"
            rm -f "$HOME_DIR/config/config.toml.bak"
            
            # Additional thorough cleanup for AppHash errors
            print_status "🔧 Performing thorough cleanup..."
            rm -rf "$HOME_DIR/data" 2>/dev/null || true
            rm -rf "$HOME_DIR/wasm" 2>/dev/null || true
            rm -f "$HOME_DIR/config/config.toml" 2>/dev/null || true
            rm -rf "$HOME_DIR/logs" 2>/dev/null || true
            
            # Always restore genesis.json to prevent startup failures
            print_status "🔧 Restoring genesis configuration..."
            GENESIS_DATA=$(curl -fsS --connect-timeout 5 --max-time 30 "$GENESIS_RPC/genesis" 2>/dev/null)
            if [ -n "$GENESIS_DATA" ]; then
                echo "$GENESIS_DATA" | jq -r '.result.genesis' > "$HOME_DIR/config/genesis.json"
                if [ -s "$HOME_DIR/config/genesis.json" ] && jq -e '.chain_id' "$HOME_DIR/config/genesis.json" >/dev/null 2>&1; then
                    print_success "✅ Genesis configuration restored"
                else
                    print_error "⚠️ Failed to restore genesis - manual intervention may be needed"
                fi
            else
                print_error "⚠️ Failed to fetch genesis from $GENESIS_RPC - manual intervention may be needed"
            fi
            
            print_success "✅ Blockchain data reset completely"
            print_status "Node will be completely re-initialized on next start"
            print_status "Start the node to re-sync: push-validator-manager start"
        fi
        ;;
        
    setup-nginx)
        if [ -z "${2:-}" ]; then
            print_error "❌ Domain required for NGINX setup"
            echo "Usage: push-validator-manager setup-nginx yourdomain.com"
            exit 1
        fi
        bash "$SCRIPT_DIR/scripts/setup-nginx.sh" "$2"
        ;;
        
    setup-logs)
        bash "$SCRIPT_DIR/scripts/setup-log-rotation.sh"
        ;;
        
    backup)
        bash "$SCRIPT_DIR/scripts/backup.sh"
        ;;
        
    recover|snapshot-recover)
        show_banner
        print_header "🔄 Manual Snapshot Recovery"
        echo
        print_status "This will recover the node using state sync from snapshots"
        print_warning "⚠️ This will reset your blockchain data (keys will be preserved)"
        echo
        read -p "Continue with recovery? (yes/no): " confirm
        if [[ "$confirm" =~ ^[Yy][Ee][Ss]$ ]]; then
            # Reset recovery attempts for manual trigger
            recovery_attempts=0
            recover_from_snapshot "manual recovery requested"
        else
            print_status "Recovery cancelled"
        fi
        ;;
        
    recovery-status)
        print_header "📊 Recovery Configuration Status"
        echo -e "${GREEN}══════════════════════════════════════${NC}"
        echo -e "  ${BOLD}Auto Recovery:${NC} $([ "$AUTO_RECOVERY_ENABLED" = "true" ] && echo "${GREEN}Enabled${NC}" || echo "${RED}Disabled${NC}")"
        echo -e "  ${BOLD}Stall Threshold:${NC} ${SYNC_STALL_THRESHOLD} seconds"
        echo -e "  ${BOLD}Recovery Attempts:${NC} ${recovery_attempts}/${MAX_RECOVERY_ATTEMPTS}"
        echo -e "  ${BOLD}Backoff Period:${NC} ${RECOVERY_BACKOFF} seconds"
        echo -e "  ${BOLD}Snapshot RPC:${NC} ${SNAPSHOT_RPC}"
        echo -e "  ${BOLD}Backup Before Recovery:${NC} $([ "$BACKUP_BEFORE_RECOVERY" = "true" ] && echo "${GREEN}Yes${NC}" || echo "${YELLOW}No${NC}")"
        echo
        if [ $recovery_attempts -ge $MAX_RECOVERY_ATTEMPTS ]; then
            print_warning "⚠️ Maximum recovery attempts reached. Reset with: export recovery_attempts=0"
        fi
        ;;
        
    monitor-state-sync)
        # Enhanced state sync monitoring with visual progress bars
        if ! is_node_running; then
            print_error "❌ Node is not running"
            echo "Start the node first: push-validator-manager start"
            exit 1
        fi
        
        # Check if state sync is configured or in progress
        phase=$(detect_state_sync_phase)
        if [ "$phase" = "completed" ]; then
            print_success "✅ State sync already completed"
            show_status
            exit 0
        elif [ "$phase" = "failed" ]; then
            print_error "❌ State sync failed"
            echo "Try recovery: push-validator-manager recover"
            exit 1
        fi
        
        # Start monitoring with enhanced progress display
        monitor_state_sync true
        ;;
        
    help|--help|-h|"")
        show_help
        ;;
        
    *)
        print_error "❌ Unknown command: $1"
        echo "Use 'push-validator-manager help' for usage information"
        exit 1
        ;;
esac
